{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spacy.lang.id import Indonesian\n",
    "from spacy.lang.id.stop_words import STOP_WORDS\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Indonesian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Tagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jakarta, Di jejaring sosial, banyak beredar in...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Isu bahwa ikan lele mengandung sel kanker di j...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bagi penikmat kuliner dengan bahan dasar ikan ...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ikan lele merupakan salah satu makanan favorit...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ikan lele merupakan bahan makanan yang cukup p...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SURABAYA, KOMPAS.com - \"Dalam sesuap daging ik...</td>\n",
       "      <td>hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bahaya Mengkonsumsi Ikan Lele Yang Mengandung ...</td>\n",
       "      <td>hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Di jejaring sosial, banyak beredar informasi y...</td>\n",
       "      <td>hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Jakarta, Sebuah artikel yang cukup viral di in...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Pada dasarnya tidak ada makanan yang membawa s...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           Articles Tagging\n",
       "0   1  Jakarta, Di jejaring sosial, banyak beredar in...   valid\n",
       "1   2  Isu bahwa ikan lele mengandung sel kanker di j...   valid\n",
       "2   3  Bagi penikmat kuliner dengan bahan dasar ikan ...   valid\n",
       "3   4  Ikan lele merupakan salah satu makanan favorit...   valid\n",
       "4   5  Ikan lele merupakan bahan makanan yang cukup p...   valid\n",
       "5   6  SURABAYA, KOMPAS.com - \"Dalam sesuap daging ik...    hoax\n",
       "6   7  Bahaya Mengkonsumsi Ikan Lele Yang Mengandung ...    hoax\n",
       "7   8  Di jejaring sosial, banyak beredar informasi y...    hoax\n",
       "8   9  Jakarta, Sebuah artikel yang cukup viral di in...   valid\n",
       "9  10  Pada dasarnya tidak ada makanan yang membawa s...   valid"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"News-Articles-Dataset.xls\", sheet_name = \"berita\", na_values = ' ')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Tagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jakarta, Di jejaring sosial, banyak beredar in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Isu bahwa ikan lele mengandung sel kanker di j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bagi penikmat kuliner dengan bahan dasar ikan ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ikan lele merupakan salah satu makanan favorit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ikan lele merupakan bahan makanan yang cukup p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SURABAYA, KOMPAS.com - \"Dalam sesuap daging ik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bahaya Mengkonsumsi Ikan Lele Yang Mengandung ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Di jejaring sosial, banyak beredar informasi y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Jakarta, Sebuah artikel yang cukup viral di in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Pada dasarnya tidak ada makanan yang membawa s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           Articles  Tagging\n",
       "0   1  Jakarta, Di jejaring sosial, banyak beredar in...        1\n",
       "1   2  Isu bahwa ikan lele mengandung sel kanker di j...        1\n",
       "2   3  Bagi penikmat kuliner dengan bahan dasar ikan ...        1\n",
       "3   4  Ikan lele merupakan salah satu makanan favorit...        1\n",
       "4   5  Ikan lele merupakan bahan makanan yang cukup p...        1\n",
       "5   6  SURABAYA, KOMPAS.com - \"Dalam sesuap daging ik...        0\n",
       "6   7  Bahaya Mengkonsumsi Ikan Lele Yang Mengandung ...        0\n",
       "7   8  Di jejaring sosial, banyak beredar informasi y...        0\n",
       "8   9  Jakarta, Sebuah artikel yang cukup viral di in...        1\n",
       "9  10  Pada dasarnya tidak ada makanan yang membawa s...        1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace tagging with numeric value\n",
    "# 1 for valid article \n",
    "# 0 for hoax article\n",
    "df.Tagging.replace(['valid', 'hoax'], [1, 0], inplace= True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sebutlah',\n",
       " 'seluruhnya',\n",
       " 'jangankan',\n",
       " 'datang',\n",
       " 'sela',\n",
       " 'sebagainya',\n",
       " 'waktunya',\n",
       " 'seketika',\n",
       " 'tiga',\n",
       " 'mendapat',\n",
       " 'ataupun',\n",
       " 'biasa',\n",
       " 'seorang',\n",
       " 'khususnya',\n",
       " 'sepertinya',\n",
       " 'bermacam',\n",
       " 'toh',\n",
       " 'manalagi',\n",
       " 'tuturnya',\n",
       " 'bersiap',\n",
       " 'dilihat',\n",
       " 'mempersiapkan',\n",
       " 'bakalan',\n",
       " 'bawah',\n",
       " 'dari',\n",
       " 'mereka',\n",
       " 'jadi',\n",
       " 'meminta',\n",
       " 'bermaksud',\n",
       " 'janganlah',\n",
       " 'berapa',\n",
       " 'jumlah',\n",
       " 'bermula',\n",
       " 'sebutnya',\n",
       " 'dimintai',\n",
       " 'siapakah',\n",
       " 'bertanya-tanya',\n",
       " 'sendirian',\n",
       " 'pada',\n",
       " 'sejak',\n",
       " 'siap',\n",
       " 'sekaligus',\n",
       " 'juga',\n",
       " 'mengibaratkannya',\n",
       " 'tandas',\n",
       " 'malah',\n",
       " 'selaku',\n",
       " 'tersampaikan',\n",
       " 'depan',\n",
       " 'semaunya',\n",
       " 'tidaklah',\n",
       " 'mendatang',\n",
       " 'segala',\n",
       " 'tampak',\n",
       " 'kepada',\n",
       " 'cuma',\n",
       " 'dimulailah',\n",
       " 'semata',\n",
       " 'sebelumnya',\n",
       " 'ditunjuk',\n",
       " 'masing',\n",
       " 'menunjuknya',\n",
       " 'bermacam-macam',\n",
       " 'jawaban',\n",
       " 'itulah',\n",
       " 'perlunya',\n",
       " 'kemudian',\n",
       " 'kala',\n",
       " 'setiap',\n",
       " 'sejumlah',\n",
       " 'selama',\n",
       " 'sempat',\n",
       " 'kamulah',\n",
       " 'kalaupun',\n",
       " 'kitalah',\n",
       " 'berupa',\n",
       " 'benarlah',\n",
       " 'rupanya',\n",
       " 'pertanyakan',\n",
       " 'daripada',\n",
       " 'sedikitnya',\n",
       " 'dimulainya',\n",
       " 'macam',\n",
       " 'diperlukannya',\n",
       " 'diingatkan',\n",
       " 'berujar',\n",
       " 'tadi',\n",
       " 'wong',\n",
       " 'melalui',\n",
       " 'dimaksud',\n",
       " 'semampu',\n",
       " 'bisakah',\n",
       " 'sini',\n",
       " 'berikan',\n",
       " 'tanya',\n",
       " 'beginian',\n",
       " 'para',\n",
       " 'sekitarnya',\n",
       " 'apalagi',\n",
       " 'semisal',\n",
       " 'suatu',\n",
       " 'termasuk',\n",
       " 'sendiri',\n",
       " 'menaiki',\n",
       " 'kamilah',\n",
       " 'ibaratnya',\n",
       " 'diinginkan',\n",
       " 'agaknya',\n",
       " 'dini',\n",
       " 'akhiri',\n",
       " 'diminta',\n",
       " 'didapat',\n",
       " 'sebelum',\n",
       " 'supaya',\n",
       " 'hendaknya',\n",
       " 'dahulu',\n",
       " 'mulailah',\n",
       " 'ia',\n",
       " 'ke',\n",
       " 'begitukah',\n",
       " 'tak',\n",
       " 'dua',\n",
       " 'kalaulah',\n",
       " 'berjumlah',\n",
       " 'keinginan',\n",
       " 'sebaliknya',\n",
       " 'disebutkannya',\n",
       " 'serupa',\n",
       " 'dirinya',\n",
       " 'diucapkannya',\n",
       " 'semata-mata',\n",
       " 'berawal',\n",
       " 'sekiranya',\n",
       " 'sama',\n",
       " 'ada',\n",
       " 'kurang',\n",
       " 'lanjut',\n",
       " 'bukanlah',\n",
       " 'dituturkan',\n",
       " 'kepadanya',\n",
       " 'pihak',\n",
       " 'mendatangi',\n",
       " 'digunakan',\n",
       " 'meskipun',\n",
       " 'dimisalkan',\n",
       " 'menegaskan',\n",
       " 'lamanya',\n",
       " 'menanyai',\n",
       " 'lama',\n",
       " 'diucapkan',\n",
       " 'bekerja',\n",
       " 'demikian',\n",
       " 'dijelaskan',\n",
       " 'sedang',\n",
       " 'bila',\n",
       " 'gunakan',\n",
       " 'tunjuk',\n",
       " 'dipertanyakan',\n",
       " 'apatah',\n",
       " 'dipersoalkan',\n",
       " 'keseluruhan',\n",
       " 'amat',\n",
       " 'sesuatunya',\n",
       " 'jadilah',\n",
       " 'ucapnya',\n",
       " 'begitu',\n",
       " 'bertutur',\n",
       " 'menggunakan',\n",
       " 'berdatangan',\n",
       " 'berkenaan',\n",
       " 'benar',\n",
       " 'itu',\n",
       " 'adalah',\n",
       " 'memastikan',\n",
       " 'kira',\n",
       " 'dipergunakan',\n",
       " 'percuma',\n",
       " 'selalu',\n",
       " 'tiba-tiba',\n",
       " 'menantikan',\n",
       " 'dipunyai',\n",
       " 'beri',\n",
       " 'hari',\n",
       " 'bahwa',\n",
       " 'kami',\n",
       " 'nyaris',\n",
       " 'sekalipun',\n",
       " 'seperti',\n",
       " 'walaupun',\n",
       " 'antara',\n",
       " 'tahun',\n",
       " 'dijawab',\n",
       " 'dulu',\n",
       " 'memberi',\n",
       " 'diberikan',\n",
       " 'karena',\n",
       " 'menuju',\n",
       " 'naik',\n",
       " 'baru',\n",
       " 'berbagai',\n",
       " 'menuturkan',\n",
       " 'belumlah',\n",
       " 'masih',\n",
       " 'beberapa',\n",
       " 'dikatakannya',\n",
       " 'mengerjakan',\n",
       " 'sebetulnya',\n",
       " 'bilakah',\n",
       " 'demikianlah',\n",
       " 'sebisanya',\n",
       " 'segalanya',\n",
       " 'masihkah',\n",
       " 'yaitu',\n",
       " 'bagaimanakah',\n",
       " 'ingat-ingat',\n",
       " 'balik',\n",
       " 'dikatakan',\n",
       " 'tetap',\n",
       " 'mau',\n",
       " 'usah',\n",
       " 'kira-kira',\n",
       " 'mempergunakan',\n",
       " 'pernah',\n",
       " 'terkira',\n",
       " 'empat',\n",
       " 'diperlihatkan',\n",
       " 'panjang',\n",
       " 'sebegitu',\n",
       " 'wahai',\n",
       " 'dengan',\n",
       " 'amatlah',\n",
       " 'sekarang',\n",
       " 'se',\n",
       " 'setempat',\n",
       " 'mengingat',\n",
       " 'berapapun',\n",
       " 'berlebihan',\n",
       " 'ucap',\n",
       " 'sekurang-kurangnya',\n",
       " 'nantinya',\n",
       " 'awal',\n",
       " 'menjelaskan',\n",
       " 'saat',\n",
       " 'makin',\n",
       " 'serta',\n",
       " 'tutur',\n",
       " 'dekat',\n",
       " 'dilalui',\n",
       " 'ibarat',\n",
       " 'seberapa',\n",
       " 'terasa',\n",
       " 'memintakan',\n",
       " 'dapat',\n",
       " 'sesudahnya',\n",
       " 'hendaklah',\n",
       " 'lainnya',\n",
       " 'adanya',\n",
       " 'diakhiri',\n",
       " 'mengingatkan',\n",
       " 'pak',\n",
       " 'jadinya',\n",
       " 'bersiap-siap',\n",
       " 'bisa',\n",
       " 'mengucapkannya',\n",
       " 'semua',\n",
       " 'mirip',\n",
       " 'rata',\n",
       " 'sama-sama',\n",
       " 'disebut',\n",
       " 'kan',\n",
       " 'paling',\n",
       " 'penting',\n",
       " 'usai',\n",
       " 'tegasnya',\n",
       " 'hal',\n",
       " 'sepanjang',\n",
       " 'setengah',\n",
       " 'menjadi',\n",
       " 'jawabnya',\n",
       " 'pertama-tama',\n",
       " 'ditunjukkan',\n",
       " 'membuat',\n",
       " 'seusai',\n",
       " 'tempat',\n",
       " 'tengah',\n",
       " 'sekitar',\n",
       " 'jikalau',\n",
       " 'kemungkinannya',\n",
       " 'mengakhiri',\n",
       " 'beginilah',\n",
       " 'kasus',\n",
       " 'setinggi',\n",
       " 'kenapa',\n",
       " 'mampukah',\n",
       " 'apa',\n",
       " 'misal',\n",
       " 'sinilah',\n",
       " 'kelihatan',\n",
       " 'melihat',\n",
       " 'wah',\n",
       " 'berakhirnya',\n",
       " 'diakhirinya',\n",
       " 'tambah',\n",
       " 'jawab',\n",
       " 'secukupnya',\n",
       " 'bertanya',\n",
       " 'lewat',\n",
       " 'diri',\n",
       " 'sebut',\n",
       " 'demi',\n",
       " 'diperlukan',\n",
       " 'sesaat',\n",
       " 'disini',\n",
       " 'telah',\n",
       " 'bukankah',\n",
       " 'jelasnya',\n",
       " 'sebenarnya',\n",
       " 'dibuatnya',\n",
       " 'kinilah',\n",
       " 'terhadapnya',\n",
       " 'kedua',\n",
       " 'bagaimanapun',\n",
       " 'baik',\n",
       " 'melihatnya',\n",
       " 'dong',\n",
       " 'setibanya',\n",
       " 'masalahnya',\n",
       " 'oleh',\n",
       " 'memerlukan',\n",
       " 'siapa',\n",
       " 'berikutnya',\n",
       " 'diungkapkan',\n",
       " 'mengetahui',\n",
       " 'seterusnya',\n",
       " 'ditegaskan',\n",
       " 'diibaratkannya',\n",
       " 'dialah',\n",
       " 'ditambahkan',\n",
       " 'ibaratkan',\n",
       " 'merasa',\n",
       " 'bahwasanya',\n",
       " 'apabila',\n",
       " 'tegas',\n",
       " 'menunjukkan',\n",
       " 'seringnya',\n",
       " 'sewaktu',\n",
       " 'hanya',\n",
       " 'teringat',\n",
       " 'ataukah',\n",
       " 'keseluruhannya',\n",
       " 'sangatlah',\n",
       " 'harusnya',\n",
       " 'sering',\n",
       " 'sebesar',\n",
       " 'perlukah',\n",
       " 'satu',\n",
       " 'kok',\n",
       " 'bahkan',\n",
       " 'disampaikan',\n",
       " 'ditujukan',\n",
       " 'bulan',\n",
       " 'sepantasnyalah',\n",
       " 'lebih',\n",
       " 'setidak-tidaknya',\n",
       " 'lain',\n",
       " 'punya',\n",
       " 'tadinya',\n",
       " 'semisalnya',\n",
       " 'memperlihatkan',\n",
       " 'ujarnya',\n",
       " 'bagi',\n",
       " 'mengenai',\n",
       " 'dan',\n",
       " 'kelihatannya',\n",
       " 'ditunjuki',\n",
       " 'kemungkinan',\n",
       " 'agar',\n",
       " 'sesampai',\n",
       " 'pastilah',\n",
       " 'tinggi',\n",
       " 'terhadap',\n",
       " 'diantara',\n",
       " 'inilah',\n",
       " 'pun',\n",
       " 'begitulah',\n",
       " 'sekadarnya',\n",
       " 'bagai',\n",
       " 'begitupun',\n",
       " 'bukannya',\n",
       " 'menanti',\n",
       " 'ditandaskan',\n",
       " 'berkali-kali',\n",
       " 'kesampaian',\n",
       " 'semampunya',\n",
       " 'soalnya',\n",
       " 'menginginkan',\n",
       " 'inikah',\n",
       " 'katakanlah',\n",
       " 'belakangan',\n",
       " 'mendatangkan',\n",
       " 'dipastikan',\n",
       " 'antar',\n",
       " 'maka',\n",
       " 'cara',\n",
       " 'semakin',\n",
       " 'aku',\n",
       " 'mengucapkan',\n",
       " 'kalau',\n",
       " 'sudah',\n",
       " 'diperbuatnya',\n",
       " 'tentu',\n",
       " 'berakhirlah',\n",
       " 'diingat',\n",
       " 'menjawab',\n",
       " 'bolehlah',\n",
       " 'mengungkapkan',\n",
       " 'berlalu',\n",
       " 'mula',\n",
       " 'boleh',\n",
       " 'ditunjuknya',\n",
       " 'sebaiknya',\n",
       " 'menanyakan',\n",
       " 'tahu',\n",
       " 'tidak',\n",
       " 'tentulah',\n",
       " 'adapun',\n",
       " 'pertanyaan',\n",
       " 'hampir',\n",
       " 'berarti',\n",
       " 'maupun',\n",
       " 'keadaan',\n",
       " 'ini',\n",
       " 'masing-masing',\n",
       " 'sebagai',\n",
       " 'sebuah',\n",
       " 'tapi',\n",
       " 'memulai',\n",
       " 'dimaksudkannya',\n",
       " 'saya',\n",
       " 'sebegini',\n",
       " 'seluruh',\n",
       " 'tetapi',\n",
       " 'keluar',\n",
       " 'ujar',\n",
       " 'asal',\n",
       " 'sesegera',\n",
       " 'pentingnya',\n",
       " 'tentunya',\n",
       " 'luar',\n",
       " 'setidaknya',\n",
       " 'hendak',\n",
       " 'menandaskan',\n",
       " 'segera',\n",
       " 'betulkah',\n",
       " 'yakni',\n",
       " 'andalah',\n",
       " 'anda',\n",
       " 'dituturkannya',\n",
       " 'didatangkan',\n",
       " 'betul',\n",
       " 'ungkapnya',\n",
       " 'guna',\n",
       " 'sudahkah',\n",
       " 'sebaik',\n",
       " 'siapapun',\n",
       " 'dijelaskannya',\n",
       " 'memungkinkan',\n",
       " 'padahal',\n",
       " 'lah',\n",
       " 'sejauh',\n",
       " 'dia',\n",
       " 'berkehendak',\n",
       " 'berakhir',\n",
       " 'dikarenakan',\n",
       " 'per',\n",
       " 'kapankah',\n",
       " 'terjadi',\n",
       " 'ibu',\n",
       " 'tidakkah',\n",
       " 'lalu',\n",
       " 'caranya',\n",
       " 'seseorang',\n",
       " 'terjadilah',\n",
       " 'sampai',\n",
       " 'sesuatu',\n",
       " 'mengatakannya',\n",
       " 'ditanya',\n",
       " 'ikut',\n",
       " 'jelaslah',\n",
       " 'diketahuinya',\n",
       " 'ditanyakan',\n",
       " 'sekali',\n",
       " 'nyatanya',\n",
       " 'sesekali',\n",
       " 'terlebih',\n",
       " 'menyeluruh',\n",
       " 'ungkap',\n",
       " 'seharusnya',\n",
       " 'tersebut',\n",
       " 'melainkan',\n",
       " 'terlalu',\n",
       " 'jumlahnya',\n",
       " 'terjadinya',\n",
       " 'bakal',\n",
       " 'sekurangnya',\n",
       " 'waktu',\n",
       " 'saling',\n",
       " 'sekalian',\n",
       " 'katanya',\n",
       " 'tampaknya',\n",
       " 'berapakah',\n",
       " 'diperkirakan',\n",
       " 'benarkah',\n",
       " 'jauh',\n",
       " 'sajalah',\n",
       " 'mana',\n",
       " 'belum',\n",
       " 'secara',\n",
       " 'sekadar',\n",
       " 'menyangkut',\n",
       " 'kata',\n",
       " 'keterlaluan',\n",
       " 'saja',\n",
       " 'sangat',\n",
       " 'sampaikan',\n",
       " 'begini',\n",
       " 'bukan',\n",
       " 'pertama',\n",
       " 'mempersoalkan',\n",
       " 'merupakan',\n",
       " 'kapanpun',\n",
       " 'beginikah',\n",
       " 'ditanyai',\n",
       " 'ingat',\n",
       " 'berapalah',\n",
       " 'sebabnya',\n",
       " 'umum',\n",
       " 'jelas',\n",
       " 'berlangsung',\n",
       " 'cukup',\n",
       " 'apaan',\n",
       " 'jika',\n",
       " 'pasti',\n",
       " 'terutama',\n",
       " 'kita',\n",
       " 'menyebutkan',\n",
       " 'yakin',\n",
       " 'sekecil',\n",
       " 'disebutkan',\n",
       " 'padanya',\n",
       " 'berada',\n",
       " 'masa',\n",
       " 'perlu',\n",
       " 'tanyakan',\n",
       " 'ketika',\n",
       " 'berlainan',\n",
       " 'merekalah',\n",
       " 'diperbuat',\n",
       " 'mengibaratkan',\n",
       " 'sudahlah',\n",
       " 'sayalah',\n",
       " 'menunjuki',\n",
       " 'semacam',\n",
       " 'menunjuk',\n",
       " 'biasanya',\n",
       " 'inginkan',\n",
       " 'tertuju',\n",
       " 'pihaknya',\n",
       " 'dimulai',\n",
       " 'memperbuat',\n",
       " 'minta',\n",
       " 'tambahnya',\n",
       " 'di',\n",
       " 'disinilah',\n",
       " 'manakala',\n",
       " 'dibuat',\n",
       " 'awalnya',\n",
       " 'nanti',\n",
       " 'diketahui',\n",
       " 'diibaratkan',\n",
       " 'memang',\n",
       " 'bagaikan',\n",
       " 'mulai',\n",
       " 'keduanya',\n",
       " 'asalkan',\n",
       " 'bersama-sama',\n",
       " 'mengapa',\n",
       " 'mungkinkah',\n",
       " 'kecil',\n",
       " 'pula',\n",
       " 'seenaknya',\n",
       " 'meski',\n",
       " 'terdapat',\n",
       " 'mendapatkan',\n",
       " 'sambil',\n",
       " 'lagian',\n",
       " 'lanjutnya',\n",
       " 'malahan',\n",
       " 'tepat',\n",
       " 'semula',\n",
       " 'turut',\n",
       " 'terbanyak',\n",
       " 'umumnya',\n",
       " 'diantaranya',\n",
       " 'akhirnya',\n",
       " 'namun',\n",
       " 'kelamaan',\n",
       " 'setelah',\n",
       " 'waduh',\n",
       " 'buat',\n",
       " 'walau',\n",
       " 'sejenak',\n",
       " 'dikira',\n",
       " 'akhir',\n",
       " 'seperlunya',\n",
       " 'berturut-turut',\n",
       " 'sepantasnya',\n",
       " 'sana',\n",
       " 'makanya',\n",
       " 'sebagian',\n",
       " 'kalian',\n",
       " 'sesama',\n",
       " 'diberikannya',\n",
       " 'sedikit',\n",
       " 'itukah',\n",
       " 'selama-lamanya',\n",
       " 'saatnya',\n",
       " 'tanyanya',\n",
       " 'selain',\n",
       " 'misalkan',\n",
       " 'dalam',\n",
       " 'olehnya',\n",
       " 'semuanya',\n",
       " 'kini',\n",
       " 'lagi',\n",
       " 'sehingga',\n",
       " 'cukupkah',\n",
       " 'sedemikian',\n",
       " 'bagian',\n",
       " 'mempertanyakan',\n",
       " 'akan',\n",
       " 'menyatakan',\n",
       " 'kelima',\n",
       " 'dimaksudnya',\n",
       " 'menanya',\n",
       " 'bersama',\n",
       " 'tanpa',\n",
       " 'hingga',\n",
       " 'ingin',\n",
       " 'mengatakan',\n",
       " 'sebagaimana',\n",
       " 'seingat',\n",
       " 'berkata',\n",
       " 'atas',\n",
       " 'yang',\n",
       " 'melakukan',\n",
       " 'terakhir',\n",
       " 'selanjutnya',\n",
       " 'dilakukan',\n",
       " 'dikerjakan',\n",
       " 'bolehkah',\n",
       " 'teringat-ingat',\n",
       " 'kamu',\n",
       " 'memperkirakan',\n",
       " 'sekali-kali',\n",
       " 'enggaknya',\n",
       " 'kembali',\n",
       " 'persoalan',\n",
       " 'berturut',\n",
       " 'atau',\n",
       " 'sedangkan',\n",
       " 'terdahulu',\n",
       " 'akankah',\n",
       " 'menambahkan',\n",
       " 'mungkin',\n",
       " 'menyiapkan',\n",
       " 'bagaimana',\n",
       " 'jelaskan',\n",
       " 'tersebutlah',\n",
       " 'lima',\n",
       " 'bung',\n",
       " 'terdiri',\n",
       " 'memisalkan',\n",
       " 'meyakini',\n",
       " 'sendirinya',\n",
       " 'pantas',\n",
       " 'menurut',\n",
       " 'artinya',\n",
       " 'sebab',\n",
       " 'enggak',\n",
       " 'memberikan',\n",
       " 'terus',\n",
       " 'entah',\n",
       " 'bapak',\n",
       " 'haruslah',\n",
       " 'berikut',\n",
       " 'mengira',\n",
       " 'mempunyai',\n",
       " 'semasih',\n",
       " 'seolah',\n",
       " 'diberi',\n",
       " 'sementara',\n",
       " 'untuk',\n",
       " 'ditunjukkannya',\n",
       " 'menyampaikan',\n",
       " 'sebaik-baiknya',\n",
       " 'dimaksudkan',\n",
       " 'memihak',\n",
       " 'besar',\n",
       " 'entahlah',\n",
       " 'sesudah',\n",
       " 'menghendaki',\n",
       " 'selamanya',\n",
       " 'rasanya',\n",
       " 'berkeinginan',\n",
       " 'karenanya',\n",
       " 'dimungkinkan',\n",
       " 'akulah',\n",
       " 'ialah',\n",
       " 'jangan',\n",
       " 'katakan',\n",
       " 'sampai-sampai',\n",
       " 'tandasnya',\n",
       " 'agak',\n",
       " 'kebetulan',\n",
       " 'sepihak',\n",
       " 'sebanyak',\n",
       " 'tentang',\n",
       " 'inginkah',\n",
       " 'apakah',\n",
       " 'kapan',\n",
       " 'soal',\n",
       " 'hanyalah',\n",
       " 'tertentu',\n",
       " 'harus',\n",
       " 'meyakinkan',\n",
       " 'cukuplah',\n",
       " 'justru',\n",
       " 'antaranya',\n",
       " 'masalah',\n",
       " 'mulanya',\n",
       " 'setiba',\n",
       " 'mampu',\n",
       " 'rasa',\n",
       " 'pukul',\n",
       " 'seolah-olah',\n",
       " 'kiranya',\n",
       " 'belakang',\n",
       " 'nah',\n",
       " 'tiba',\n",
       " 'terlihat',\n",
       " 'tiap',\n",
       " 'misalnya',\n",
       " 'ternyata',\n",
       " 'menanti-nanti',\n",
       " 'semasa',\n",
       " 'banyak']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jakarta, Di jejaring sosial, banyak beredar informasi yang menyebut lele sebagai ikan paling jorok. Dalam sesuap daging ikan lele, terkandung 3000 sel kanker. Benarkah?\\nJulukan sebagai ikan paling jorok merujuk pada sifat lele yang doyan mengonsumsi segala jenis limbah di perairan. Bahkan sebuah artikel yang cukup viral di internet menyebutkan kotoran manusia juga dijadikan pakan pada sebuah budidaya lele di Kota Haikou, China.\\nSementara itu di habitat aslinya, lele atau catfish juga dikenal sebagai spesies ikan yang sangat tangguh. Ikan ini dilengkapi alat pernapasan tambahan berupa labirin, sehingga mampu bertahan hidup dalam kondisi perairan berlumpur atau bahkan tercemar. Agaknya, fakta inilah yang memunculkan dugaan soal akumulasi racun karsinogen (penyebab kanker) di tubuh ikan lele.\\nUntungnya, ikan lele yang beredar di pasaran bukan berasal dari alam liar. Lele banyak dibudidayakan di kolam-kolam, yang mestinya bisa dikendalikan agar bebas dari pencemaran. Pakan yang diberikan juga bisa dipilih, tidak harus mengandalkan limbah.\\nYang pasti, popularitas ikan bersungut ini tidak pernah pudar, bahkan terus meningkat. Data Kementerian Kelautan dan Perikanan (KKP) menyebut produksi lele pada 2013 mencapai 543,461 ton, meningkat dari 441,217 ton pada 2012 dan 337,577 ton pada 2011.\\nKonsumsi ikan lele menurut Badan Pusat Statistik (BPS) tercatat 29,98 kg/kapita/tahun, naik dari 22,58 kg/kapita/tahun pada 2004. Di Jakarta, tak kurang dari 6000 lapak pecel lele telah terdaftar di Asosiasi Pedagang Kaki Lima Indonesia (APKLI).\\nSoal kandungan nutrisi, tak bisa dipungkiri bahwa lele adalah sumber protein berharga yang murah meriah. Fakta bahwa ikan lele juga rendah kolesterol sepertinya bakal menenggelamkan tudingan bahwa lele bisa memicu kanker. \"Saat ini belum ada penelitian yang menyatakan jika memakan lele dapat memicu kanker,\" tegas dr Dradjat R Suardi, SpB(K)Onk, ahli kanker dari Perhimpunan Onkologi Indonesia saat dihubungi detikHealth, Jumat (23/10/2015).\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleArticle = df['Articles'].values[0]\n",
    "sampleArticle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jakarta Lemma => Jakarta\n",
      ", Lemma => ,\n",
      "Di Lemma => Di\n",
      "jejaring Lemma => jejaring\n",
      "sosial Lemma => sosial\n",
      ", Lemma => ,\n",
      "banyak Lemma => banyak\n",
      "beredar Lemma => edar\n",
      "informasi Lemma => informasi\n",
      "yang Lemma => yang\n",
      "menyebut Lemma => sebut\n",
      "lele Lemma => lele\n",
      "sebagai Lemma => bagai\n",
      "ikan Lemma => ikan\n",
      "paling Lemma => paling\n",
      "jorok Lemma => jorok\n",
      ". Lemma => .\n",
      "Dalam Lemma => Dalam\n",
      "sesuap Lemma => suap\n",
      "daging Lemma => daging\n",
      "ikan Lemma => ikan\n",
      "lele Lemma => lele\n",
      ", Lemma => ,\n",
      "terkandung Lemma => kandung\n",
      "3000 Lemma => 3000\n",
      "sel Lemma => sel\n",
      "kanker Lemma => kanker\n",
      ". Lemma => .\n",
      "Benarkah Lemma => Benarkah\n",
      "? Lemma => ?\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Julukan Lemma => Julukan\n",
      "sebagai Lemma => bagai\n",
      "ikan Lemma => ikan\n",
      "paling Lemma => paling\n",
      "jorok Lemma => jorok\n",
      "merujuk Lemma => rujuk\n",
      "pada Lemma => pada\n",
      "sifat Lemma => sifat\n",
      "lele Lemma => lele\n",
      "yang Lemma => yang\n",
      "doyan Lemma => doyan\n",
      "mengonsumsi Lemma => konsumsi\n",
      "segala Lemma => segala\n",
      "jenis Lemma => jenis\n",
      "limbah Lemma => limbah\n",
      "di Lemma => di\n",
      "perairan Lemma => air\n",
      ". Lemma => .\n",
      "Bahkan Lemma => Bahkan\n",
      "sebuah Lemma => sebuah\n",
      "artikel Lemma => artikel\n",
      "yang Lemma => yang\n",
      "cukup Lemma => cukup\n",
      "viral Lemma => viral\n",
      "di Lemma => di\n",
      "internet Lemma => internet\n",
      "menyebutkan Lemma => sebut\n",
      "kotoran Lemma => kotor\n",
      "manusia Lemma => manusia\n",
      "juga Lemma => juga\n",
      "dijadikan Lemma => dijadikan\n",
      "pakan Lemma => pakan\n",
      "pada Lemma => pada\n",
      "sebuah Lemma => sebuah\n",
      "budidaya Lemma => budidaya\n",
      "lele Lemma => lele\n",
      "di Lemma => di\n",
      "Kota Lemma => Kota\n",
      "Haikou Lemma => Haikou\n",
      ", Lemma => ,\n",
      "China Lemma => China\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Sementara Lemma => Sementara\n",
      "itu Lemma => itu\n",
      "di Lemma => di\n",
      "habitat Lemma => habitat\n",
      "aslinya Lemma => aslinya\n",
      ", Lemma => ,\n",
      "lele Lemma => lele\n",
      "atau Lemma => atau\n",
      "catfish Lemma => catfish\n",
      "juga Lemma => juga\n",
      "dikenal Lemma => dikenal\n",
      "sebagai Lemma => bagai\n",
      "spesies Lemma => spesies\n",
      "ikan Lemma => ikan\n",
      "yang Lemma => yang\n",
      "sangat Lemma => sangat\n",
      "tangguh Lemma => tangguh\n",
      ". Lemma => .\n",
      "Ikan Lemma => Ikan\n",
      "ini Lemma => ini\n",
      "dilengkapi Lemma => dilengkapi\n",
      "alat Lemma => alat\n",
      "pernapasan Lemma => napas\n",
      "tambahan Lemma => tambah\n",
      "berupa Lemma => rupa\n",
      "labirin Lemma => labirin\n",
      ", Lemma => ,\n",
      "sehingga Lemma => sehingga\n",
      "mampu Lemma => mampu\n",
      "bertahan Lemma => tahan\n",
      "hidup Lemma => hidup\n",
      "dalam Lemma => dalam\n",
      "kondisi Lemma => kondisi\n",
      "perairan Lemma => air\n",
      "berlumpur Lemma => lumpur\n",
      "atau Lemma => atau\n",
      "bahkan Lemma => bahkan\n",
      "tercemar Lemma => cemar\n",
      ". Lemma => .\n",
      "Agaknya Lemma => Agaknya\n",
      ", Lemma => ,\n",
      "fakta Lemma => fakta\n",
      "inilah Lemma => inilah\n",
      "yang Lemma => yang\n",
      "memunculkan Lemma => muncul\n",
      "dugaan Lemma => duga\n",
      "soal Lemma => soal\n",
      "akumulasi Lemma => akumulasi\n",
      "racun Lemma => racun\n",
      "karsinogen Lemma => karsinogen\n",
      "( Lemma => (\n",
      "penyebab Lemma => sebab\n",
      "kanker Lemma => kanker\n",
      ") Lemma => )\n",
      "di Lemma => di\n",
      "tubuh Lemma => tubuh\n",
      "ikan Lemma => ikan\n",
      "lele Lemma => lele\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Untungnya Lemma => Untungnya\n",
      ", Lemma => ,\n",
      "ikan Lemma => ikan\n",
      "lele Lemma => lele\n",
      "yang Lemma => yang\n",
      "beredar Lemma => edar\n",
      "di Lemma => di\n",
      "pasaran Lemma => pasar\n",
      "bukan Lemma => bukan\n",
      "berasal Lemma => asal\n",
      "dari Lemma => dari\n",
      "alam Lemma => alam\n",
      "liar Lemma => liar\n",
      ". Lemma => .\n",
      "Lele Lemma => Lele\n",
      "banyak Lemma => banyak\n",
      "dibudidayakan Lemma => dibudidayakan\n",
      "di Lemma => di\n",
      "kolam Lemma => kolam\n",
      "- Lemma => -\n",
      "kolam Lemma => kolam\n",
      ", Lemma => ,\n",
      "yang Lemma => yang\n",
      "mestinya Lemma => mestinya\n",
      "bisa Lemma => bisa\n",
      "dikendalikan Lemma => dikendalikan\n",
      "agar Lemma => agar\n",
      "bebas Lemma => bebas\n",
      "dari Lemma => dari\n",
      "pencemaran Lemma => cemar\n",
      ". Lemma => .\n",
      "Pakan Lemma => Pakan\n",
      "yang Lemma => yang\n",
      "diberikan Lemma => diberikan\n",
      "juga Lemma => juga\n",
      "bisa Lemma => bisa\n",
      "dipilih Lemma => dipilih\n",
      ", Lemma => ,\n",
      "tidak Lemma => tidak\n",
      "harus Lemma => harus\n",
      "mengandalkan Lemma => andal\n",
      "limbah Lemma => limbah\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Yang Lemma => Yang\n",
      "pasti Lemma => pasti\n",
      ", Lemma => ,\n",
      "popularitas Lemma => popularitas\n",
      "ikan Lemma => ikan\n",
      "bersungut Lemma => sungut\n",
      "ini Lemma => ini\n",
      "tidak Lemma => tidak\n",
      "pernah Lemma => pernah\n",
      "pudar Lemma => pudar\n",
      ", Lemma => ,\n",
      "bahkan Lemma => bahkan\n",
      "terus Lemma => terus\n",
      "meningkat Lemma => tingkat\n",
      ". Lemma => .\n",
      "Data Lemma => Data\n",
      "Kementerian Lemma => Kementerian\n",
      "Kelautan Lemma => Kelautan\n",
      "dan Lemma => dan\n",
      "Perikanan Lemma => Perikanan\n",
      "( Lemma => (\n",
      "KKP Lemma => KKP\n",
      ") Lemma => )\n",
      "menyebut Lemma => sebut\n",
      "produksi Lemma => produksi\n",
      "lele Lemma => lele\n",
      "pada Lemma => pada\n",
      "2013 Lemma => 2013\n",
      "mencapai Lemma => capai\n",
      "543,461 Lemma => 543,461\n",
      "ton Lemma => ton\n",
      ", Lemma => ,\n",
      "meningkat Lemma => tingkat\n",
      "dari Lemma => dari\n",
      "441,217 Lemma => 441,217\n",
      "ton Lemma => ton\n",
      "pada Lemma => pada\n",
      "2012 Lemma => 2012\n",
      "dan Lemma => dan\n",
      "337,577 Lemma => 337,577\n",
      "ton Lemma => ton\n",
      "pada Lemma => pada\n",
      "2011 Lemma => 2011\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Konsumsi Lemma => Konsumsi\n",
      "ikan Lemma => ikan\n",
      "lele Lemma => lele\n",
      "menurut Lemma => turut\n",
      "Badan Lemma => Badan\n",
      "Pusat Lemma => Pusat\n",
      "Statistik Lemma => Statistik\n",
      "( Lemma => (\n",
      "BPS Lemma => BPS\n",
      ") Lemma => )\n",
      "tercatat Lemma => catat\n",
      "29,98 Lemma => 29,98\n",
      "kg Lemma => kg\n",
      "/ Lemma => /\n",
      "kapita Lemma => kapita\n",
      "/ Lemma => /\n",
      "tahun Lemma => tahun\n",
      ", Lemma => ,\n",
      "naik Lemma => naik\n",
      "dari Lemma => dari\n",
      "22,58 Lemma => 22,58\n",
      "kg Lemma => kg\n",
      "/ Lemma => /\n",
      "kapita Lemma => kapita\n",
      "/ Lemma => /\n",
      "tahun Lemma => tahun\n",
      "pada Lemma => pada\n",
      "2004 Lemma => 2004\n",
      ". Lemma => .\n",
      "Di Lemma => Di\n",
      "Jakarta Lemma => Jakarta\n",
      ", Lemma => ,\n",
      "tak Lemma => tak\n",
      "kurang Lemma => kurang\n",
      "dari Lemma => dari\n",
      "6000 Lemma => 6000\n",
      "lapak Lemma => lapak\n",
      "pecel Lemma => pecel\n",
      "lele Lemma => lele\n",
      "telah Lemma => telah\n",
      "terdaftar Lemma => daftar\n",
      "di Lemma => di\n",
      "Asosiasi Lemma => Asosiasi\n",
      "Pedagang Lemma => Pedagang\n",
      "Kaki Lemma => Kaki\n",
      "Lima Lemma => Lima\n",
      "Indonesia Lemma => Indonesia\n",
      "( Lemma => (\n",
      "APKLI Lemma => APKLI\n",
      ") Lemma => )\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Soal Lemma => Soal\n",
      "kandungan Lemma => kandung\n",
      "nutrisi Lemma => nutrisi\n",
      ", Lemma => ,\n",
      "tak Lemma => tak\n",
      "bisa Lemma => bisa\n",
      "dipungkiri Lemma => dipungkiri\n",
      "bahwa Lemma => bahwa\n",
      "lele Lemma => lele\n",
      "adalah Lemma => adalah\n",
      "sumber Lemma => sumber\n",
      "protein Lemma => protein\n",
      "berharga Lemma => harga\n",
      "yang Lemma => yang\n",
      "murah Lemma => murah\n",
      "meriah Lemma => riah\n",
      ". Lemma => .\n",
      "Fakta Lemma => Fakta\n",
      "bahwa Lemma => bahwa\n",
      "ikan Lemma => ikan\n",
      "lele Lemma => lele\n",
      "juga Lemma => juga\n",
      "rendah Lemma => rendah\n",
      "kolesterol Lemma => kolesterol\n",
      "sepertinya Lemma => seperti\n",
      "bakal Lemma => bakal\n",
      "menenggelamkan Lemma => tenggelam\n",
      "tudingan Lemma => tuding\n",
      "bahwa Lemma => bahwa\n",
      "lele Lemma => lele\n",
      "bisa Lemma => bisa\n",
      "memicu Lemma => picu\n",
      "kanker Lemma => kanker\n",
      ". Lemma => .\n",
      "\" Lemma => \"\n",
      "Saat Lemma => Saat\n",
      "ini Lemma => ini\n",
      "belum Lemma => belum\n",
      "ada Lemma => ada\n",
      "penelitian Lemma => teliti\n",
      "yang Lemma => yang\n",
      "menyatakan Lemma => nyata\n",
      "jika Lemma => jika\n",
      "memakan Lemma => makan\n",
      "lele Lemma => lele\n",
      "dapat Lemma => dapat\n",
      "memicu Lemma => picu\n",
      "kanker Lemma => kanker\n",
      ", Lemma => ,\n",
      "\" Lemma => \"\n",
      "tegas Lemma => tegas\n",
      "dr Lemma => dr\n",
      "Dradjat Lemma => Dradjat\n",
      "R Lemma => R\n",
      "Suardi Lemma => Suardi\n",
      ", Lemma => ,\n",
      "SpB(K)Onk Lemma => SpB(K)Onk\n",
      ", Lemma => ,\n",
      "ahli Lemma => ahli\n",
      "kanker Lemma => kanker\n",
      "dari Lemma => dari\n",
      "Perhimpunan Lemma => Perhimpunan\n",
      "Onkologi Lemma => Onkologi\n",
      "Indonesia Lemma => Indonesia\n",
      "saat Lemma => saat\n",
      "dihubungi Lemma => dihubungi\n",
      "detikHealth Lemma => detikHealth\n",
      ", Lemma => ,\n",
      "Jumat Lemma => Jumat\n",
      "( Lemma => (\n",
      "23 Lemma => 23\n",
      "/ Lemma => /\n",
      "10 Lemma => 10\n",
      "/ Lemma => /\n",
      "2015 Lemma => 2015\n",
      ") Lemma => )\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "docx = nlp(sampleArticle)\n",
    "for word in docx: \n",
    "    print(word.text,\"Lemma =>\",word.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jakarta\n",
      "Di\n",
      "jejaring\n",
      "sosial\n",
      "beredar\n",
      "informasi\n",
      "menyebut\n",
      "lele\n",
      "ikan\n",
      "jorok\n",
      "Dalam\n",
      "sesuap\n",
      "daging\n",
      "ikan\n",
      "lele\n",
      "terkandung\n",
      "3000\n",
      "sel\n",
      "kanker\n",
      "Benarkah\n",
      "\n",
      "\n",
      "Julukan\n",
      "ikan\n",
      "jorok\n",
      "merujuk\n",
      "sifat\n",
      "lele\n",
      "doyan\n",
      "mengonsumsi\n",
      "jenis\n",
      "limbah\n",
      "perairan\n",
      "Bahkan\n",
      "artikel\n",
      "viral\n",
      "internet\n",
      "kotoran\n",
      "manusia\n",
      "dijadikan\n",
      "pakan\n",
      "budidaya\n",
      "lele\n",
      "Kota\n",
      "Haikou\n",
      "China\n",
      "\n",
      "\n",
      "Sementara\n",
      "habitat\n",
      "aslinya\n",
      "lele\n",
      "catfish\n",
      "dikenal\n",
      "spesies\n",
      "ikan\n",
      "tangguh\n",
      "Ikan\n",
      "dilengkapi\n",
      "alat\n",
      "pernapasan\n",
      "tambahan\n",
      "labirin\n",
      "bertahan\n",
      "hidup\n",
      "kondisi\n",
      "perairan\n",
      "berlumpur\n",
      "tercemar\n",
      "Agaknya\n",
      "fakta\n",
      "memunculkan\n",
      "dugaan\n",
      "akumulasi\n",
      "racun\n",
      "karsinogen\n",
      "penyebab\n",
      "kanker\n",
      "tubuh\n",
      "ikan\n",
      "lele\n",
      "\n",
      "\n",
      "Untungnya\n",
      "ikan\n",
      "lele\n",
      "beredar\n",
      "pasaran\n",
      "berasal\n",
      "alam\n",
      "liar\n",
      "Lele\n",
      "dibudidayakan\n",
      "kolam\n",
      "kolam\n",
      "mestinya\n",
      "dikendalikan\n",
      "bebas\n",
      "pencemaran\n",
      "Pakan\n",
      "dipilih\n",
      "mengandalkan\n",
      "limbah\n",
      "\n",
      "\n",
      "Yang\n",
      "popularitas\n",
      "ikan\n",
      "bersungut\n",
      "pudar\n",
      "meningkat\n",
      "Data\n",
      "Kementerian\n",
      "Kelautan\n",
      "Perikanan\n",
      "KKP\n",
      "menyebut\n",
      "produksi\n",
      "lele\n",
      "2013\n",
      "mencapai\n",
      "543,461\n",
      "ton\n",
      "meningkat\n",
      "441,217\n",
      "ton\n",
      "2012\n",
      "337,577\n",
      "ton\n",
      "2011\n",
      "\n",
      "\n",
      "Konsumsi\n",
      "ikan\n",
      "lele\n",
      "Badan\n",
      "Pusat\n",
      "Statistik\n",
      "BPS\n",
      "tercatat\n",
      "29,98\n",
      "kg\n",
      "kapita\n",
      "22,58\n",
      "kg\n",
      "kapita\n",
      "2004\n",
      "Di\n",
      "Jakarta\n",
      "6000\n",
      "lapak\n",
      "pecel\n",
      "lele\n",
      "terdaftar\n",
      "Asosiasi\n",
      "Pedagang\n",
      "Kaki\n",
      "Lima\n",
      "Indonesia\n",
      "APKLI\n",
      "\n",
      "\n",
      "Soal\n",
      "kandungan\n",
      "nutrisi\n",
      "dipungkiri\n",
      "lele\n",
      "sumber\n",
      "protein\n",
      "berharga\n",
      "murah\n",
      "meriah\n",
      "Fakta\n",
      "ikan\n",
      "lele\n",
      "rendah\n",
      "kolesterol\n",
      "menenggelamkan\n",
      "tudingan\n",
      "lele\n",
      "memicu\n",
      "kanker\n",
      "Saat\n",
      "penelitian\n",
      "memakan\n",
      "lele\n",
      "memicu\n",
      "kanker\n",
      "dr\n",
      "Dradjat\n",
      "R\n",
      "Suardi\n",
      "SpB(K)Onk\n",
      "ahli\n",
      "kanker\n",
      "Perhimpunan\n",
      "Onkologi\n",
      "Indonesia\n",
      "dihubungi\n",
      "detikHealth\n",
      "Jumat\n",
      "23\n",
      "10\n",
      "2015\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering out Stopwords and Punctuations\n",
    "for word in docx:\n",
    "    if word.is_stop == False and not word.is_punct:\n",
    "        if word.is_stop != True and not word.is_punct:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Jakarta,\n",
       " Di,\n",
       " jejaring,\n",
       " sosial,\n",
       " beredar,\n",
       " informasi,\n",
       " menyebut,\n",
       " lele,\n",
       " ikan,\n",
       " jorok,\n",
       " Dalam,\n",
       " sesuap,\n",
       " daging,\n",
       " ikan,\n",
       " lele,\n",
       " terkandung,\n",
       " 3000,\n",
       " sel,\n",
       " kanker,\n",
       " Benarkah,\n",
       " ,\n",
       " Julukan,\n",
       " ikan,\n",
       " jorok,\n",
       " merujuk,\n",
       " sifat,\n",
       " lele,\n",
       " doyan,\n",
       " mengonsumsi,\n",
       " jenis,\n",
       " limbah,\n",
       " perairan,\n",
       " Bahkan,\n",
       " artikel,\n",
       " viral,\n",
       " internet,\n",
       " kotoran,\n",
       " manusia,\n",
       " dijadikan,\n",
       " pakan,\n",
       " budidaya,\n",
       " lele,\n",
       " Kota,\n",
       " Haikou,\n",
       " China,\n",
       " ,\n",
       " Sementara,\n",
       " habitat,\n",
       " aslinya,\n",
       " lele,\n",
       " catfish,\n",
       " dikenal,\n",
       " spesies,\n",
       " ikan,\n",
       " tangguh,\n",
       " Ikan,\n",
       " dilengkapi,\n",
       " alat,\n",
       " pernapasan,\n",
       " tambahan,\n",
       " labirin,\n",
       " bertahan,\n",
       " hidup,\n",
       " kondisi,\n",
       " perairan,\n",
       " berlumpur,\n",
       " tercemar,\n",
       " Agaknya,\n",
       " fakta,\n",
       " memunculkan,\n",
       " dugaan,\n",
       " akumulasi,\n",
       " racun,\n",
       " karsinogen,\n",
       " penyebab,\n",
       " kanker,\n",
       " tubuh,\n",
       " ikan,\n",
       " lele,\n",
       " ,\n",
       " Untungnya,\n",
       " ikan,\n",
       " lele,\n",
       " beredar,\n",
       " pasaran,\n",
       " berasal,\n",
       " alam,\n",
       " liar,\n",
       " Lele,\n",
       " dibudidayakan,\n",
       " kolam,\n",
       " kolam,\n",
       " mestinya,\n",
       " dikendalikan,\n",
       " bebas,\n",
       " pencemaran,\n",
       " Pakan,\n",
       " dipilih,\n",
       " mengandalkan,\n",
       " limbah,\n",
       " ,\n",
       " Yang,\n",
       " popularitas,\n",
       " ikan,\n",
       " bersungut,\n",
       " pudar,\n",
       " meningkat,\n",
       " Data,\n",
       " Kementerian,\n",
       " Kelautan,\n",
       " Perikanan,\n",
       " KKP,\n",
       " menyebut,\n",
       " produksi,\n",
       " lele,\n",
       " 2013,\n",
       " mencapai,\n",
       " 543,461,\n",
       " ton,\n",
       " meningkat,\n",
       " 441,217,\n",
       " ton,\n",
       " 2012,\n",
       " 337,577,\n",
       " ton,\n",
       " 2011,\n",
       " ,\n",
       " Konsumsi,\n",
       " ikan,\n",
       " lele,\n",
       " Badan,\n",
       " Pusat,\n",
       " Statistik,\n",
       " BPS,\n",
       " tercatat,\n",
       " 29,98,\n",
       " kg,\n",
       " kapita,\n",
       " 22,58,\n",
       " kg,\n",
       " kapita,\n",
       " 2004,\n",
       " Di,\n",
       " Jakarta,\n",
       " 6000,\n",
       " lapak,\n",
       " pecel,\n",
       " lele,\n",
       " terdaftar,\n",
       " Asosiasi,\n",
       " Pedagang,\n",
       " Kaki,\n",
       " Lima,\n",
       " Indonesia,\n",
       " APKLI,\n",
       " ,\n",
       " Soal,\n",
       " kandungan,\n",
       " nutrisi,\n",
       " dipungkiri,\n",
       " lele,\n",
       " sumber,\n",
       " protein,\n",
       " berharga,\n",
       " murah,\n",
       " meriah,\n",
       " Fakta,\n",
       " ikan,\n",
       " lele,\n",
       " rendah,\n",
       " kolesterol,\n",
       " menenggelamkan,\n",
       " tudingan,\n",
       " lele,\n",
       " memicu,\n",
       " kanker,\n",
       " Saat,\n",
       " penelitian,\n",
       " memakan,\n",
       " lele,\n",
       " memicu,\n",
       " kanker,\n",
       " dr,\n",
       " Dradjat,\n",
       " R,\n",
       " Suardi,\n",
       " SpB(K)Onk,\n",
       " ahli,\n",
       " kanker,\n",
       " Perhimpunan,\n",
       " Onkologi,\n",
       " Indonesia,\n",
       " dihubungi,\n",
       " detikHealth,\n",
       " Jumat,\n",
       " 23,\n",
       " 10,\n",
       " 2015,\n",
       " ]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop words and Punctuation In List Comprehension\n",
    "[ word for word in docx if word.is_stop == False and not word.is_punct ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the punctuations of string module\n",
    "punctuations = string.punctuation\n",
    "# Creating a Spacy Parser\n",
    "parser = Indonesian()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(sentence):\n",
    "    mytokens = parser(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jakarta',\n",
       " 'jejaring',\n",
       " 'sosial',\n",
       " 'edar',\n",
       " 'informasi',\n",
       " 'lele',\n",
       " 'ikan',\n",
       " 'jorok',\n",
       " 'suap',\n",
       " 'daging',\n",
       " 'ikan',\n",
       " 'lele',\n",
       " 'kandung',\n",
       " '3000',\n",
       " 'sel',\n",
       " 'kanker',\n",
       " 'julukan',\n",
       " 'ikan',\n",
       " 'jorok',\n",
       " 'rujuk',\n",
       " 'sifat',\n",
       " 'lele',\n",
       " 'doyan',\n",
       " 'konsumsi',\n",
       " 'jenis',\n",
       " 'limbah',\n",
       " 'air',\n",
       " 'artikel',\n",
       " 'viral',\n",
       " 'internet',\n",
       " 'kotor',\n",
       " 'manusia',\n",
       " 'dijadikan',\n",
       " 'pakan',\n",
       " 'budidaya',\n",
       " 'lele',\n",
       " 'kota',\n",
       " 'haikou',\n",
       " 'china',\n",
       " 'habitat',\n",
       " 'aslinya',\n",
       " 'lele',\n",
       " 'catfish',\n",
       " 'dikenal',\n",
       " 'spesies',\n",
       " 'ikan',\n",
       " 'tangguh',\n",
       " 'ikan',\n",
       " 'dilengkapi',\n",
       " 'alat',\n",
       " 'napas',\n",
       " 'rupa',\n",
       " 'labirin',\n",
       " 'tahan',\n",
       " 'hidup',\n",
       " 'kondisi',\n",
       " 'air',\n",
       " 'lumpur',\n",
       " 'cemar',\n",
       " 'fakta',\n",
       " 'muncul',\n",
       " 'duga',\n",
       " 'akumulasi',\n",
       " 'racun',\n",
       " 'karsinogen',\n",
       " 'kanker',\n",
       " 'tubuh',\n",
       " 'ikan',\n",
       " 'lele',\n",
       " 'untungnya',\n",
       " 'ikan',\n",
       " 'lele',\n",
       " 'edar',\n",
       " 'pasar',\n",
       " 'alam',\n",
       " 'liar',\n",
       " 'lele',\n",
       " 'dibudidayakan',\n",
       " 'kolam',\n",
       " 'kolam',\n",
       " 'mestinya',\n",
       " 'dikendalikan',\n",
       " 'bebas',\n",
       " 'cemar',\n",
       " 'pakan',\n",
       " 'dipilih',\n",
       " 'andal',\n",
       " 'limbah',\n",
       " 'popularitas',\n",
       " 'ikan',\n",
       " 'sungut',\n",
       " 'pudar',\n",
       " 'tingkat',\n",
       " 'data',\n",
       " 'kementerian',\n",
       " 'kelautan',\n",
       " 'perikanan',\n",
       " 'kkp',\n",
       " 'produksi',\n",
       " 'lele',\n",
       " '2013',\n",
       " 'capai',\n",
       " '543,461',\n",
       " 'ton',\n",
       " 'tingkat',\n",
       " '441,217',\n",
       " 'ton',\n",
       " '2012',\n",
       " '337,577',\n",
       " 'ton',\n",
       " '2011',\n",
       " 'konsumsi',\n",
       " 'ikan',\n",
       " 'lele',\n",
       " 'badan',\n",
       " 'pusat',\n",
       " 'statistik',\n",
       " 'bps',\n",
       " 'catat',\n",
       " '29,98',\n",
       " 'kg',\n",
       " 'kapita',\n",
       " '22,58',\n",
       " 'kg',\n",
       " 'kapita',\n",
       " '2004',\n",
       " 'jakarta',\n",
       " '6000',\n",
       " 'lapak',\n",
       " 'pecel',\n",
       " 'lele',\n",
       " 'daftar',\n",
       " 'asosiasi',\n",
       " 'pedagang',\n",
       " 'kaki',\n",
       " 'indonesia',\n",
       " 'apkli',\n",
       " 'kandung',\n",
       " 'nutrisi',\n",
       " 'dipungkiri',\n",
       " 'lele',\n",
       " 'sumber',\n",
       " 'protein',\n",
       " 'harga',\n",
       " 'murah',\n",
       " 'riah',\n",
       " 'fakta',\n",
       " 'ikan',\n",
       " 'lele',\n",
       " 'rendah',\n",
       " 'kolesterol',\n",
       " 'tenggelam',\n",
       " 'tuding',\n",
       " 'lele',\n",
       " 'picu',\n",
       " 'kanker',\n",
       " 'teliti',\n",
       " 'nyata',\n",
       " 'makan',\n",
       " 'lele',\n",
       " 'picu',\n",
       " 'kanker',\n",
       " 'dr',\n",
       " 'dradjat',\n",
       " 'r',\n",
       " 'suardi',\n",
       " 'spb(k)onk',\n",
       " 'ahli',\n",
       " 'kanker',\n",
       " 'perhimpunan',\n",
       " 'onkologi',\n",
       " 'indonesia',\n",
       " 'dihubungi',\n",
       " 'detikhealth',\n",
       " 'jumat',\n",
       " '23',\n",
       " '10',\n",
       " '2015']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(sampleArticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}    \n",
    "\n",
    "# Basic function to clean the text \n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "vectorizer = CountVectorizer(tokenizer = tokenizer, ngram_range=(1,1)) \n",
    "classifier = LinearSVC()\n",
    "nbClassifier = GaussianNB()\n",
    "mNbClassifier = MultinomialNB()\n",
    "svmClassifier = svm.SVC()\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "votingClassifier = VotingClassifier(estimators=[('KNN', knnClassifier),\n",
    "                                                ('NaiveBayes', mNbClassifier), \n",
    "                                                ('SVM', svmClassifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tfidf\n",
    "tfvectorizer = TfidfVectorizer(tokenizer = tokenizer, max_df= 0.5, min_df=2, max_features = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Features and Labels\n",
    "X = df['Articles']\n",
    "ylabels = df['Tagging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', tfvectorizer),\n",
    "                 ('to_dense', DenseTransformer()),\n",
    "                 ('clf', votingClassifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cleaner', <__main__.predictors object at 0x1a23950a20>), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=600, min_df=2,\n",
       "        ngram...l=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None))])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit our data\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.58      0.71        19\n",
      "          1       0.79      0.97      0.87        31\n",
      "\n",
      "avg / total       0.84      0.82      0.81        50\n",
      "\n",
      "[[11  8]\n",
      " [ 1 30]]\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predicting with a test dataset\n",
    "sample_prediction = pipe.predict(X_test)\n",
    "report = classification_report(y_test, sample_prediction)\n",
    "print(report)\n",
    "\n",
    "confusion = confusion_matrix(y_test, sample_prediction)\n",
    "print(confusion)\n",
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "print(FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-334f6d9e559d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameter = {\n",
    "    \"clf__C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"clf__gamma\": [0.01, 0.1, 1, 10, 100],    \n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipe, param_grid=parameter, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Results\n",
    "# 1 = Valid article\n",
    "# 0 = Hoax article\n",
    "for (sample,pred) in zip(X_test,sample_prediction):\n",
    "    print(sample,\"Prediction=>\",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.82\n",
      "Accuracy:  0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy: \",pipe.score(X_test,y_test))\n",
    "print(\"Accuracy: \",pipe.score(X_test,sample_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "tfvectorizer = TfidfVectorizer(tokenizer = tokenizer, max_df= 0.5, min_df=2, max_features = 100)\n",
    "\n",
    "mNbClassifier = MultinomialNB(alpha=0.5, fit_prior=True, class_prior=None)\n",
    "svmClassifier = svm.SVC()\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# votingClassifier = VotingClassifier(estimators=[('KNN', knnClassifier),\n",
    "#                                                 ('NaiveBayes', mNbClassifier), \n",
    "#                                                 ('SVM', svmClassifier)])\n",
    "\n",
    "votingClassifier = VotingClassifier(estimators=[('KNN', knnClassifier),\n",
    "                                                ('NaiveBayes', mNbClassifier), \n",
    "                                                ('SVM', svmClassifier)], voting='hard')\n",
    "\n",
    "\n",
    "\n",
    "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', tfvectorizer),\n",
    "                 ('to_dense', DenseTransformer()),\n",
    "                 ('classifier', votingClassifier)])\n",
    "# Fit our data\n",
    "pipe.fit(X_train,y_train)\n",
    "print(\"Accuracy: \",pipe.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= tfvectorizer.fit_transform(df['Articles'])\n",
    "df1 = pd.DataFrame(x.toarray(), columns=tfvectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfvectorizer.get_feature_names()\n",
    "corpus_index = [n for n in corpus]\n",
    "import pandas as pd\n",
    "df3 = pd.DataFrame(tfs.T.todense(), index=feature_names, columns=corpus_index)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# from collections import defaultdict\n",
    "\n",
    "# refsets = defaultdict(set)\n",
    "# testsets = defaultdict(set)\n",
    "# labels = []\n",
    "# tests = []\n",
    "# for i, (feats, label) in enumerate(X_test,sample_prediction):\n",
    "#     refsets[label].add(i)\n",
    "#     observed = classifier.classify(feats)\n",
    "#     testsets[observed].add(i)\n",
    "#     labels.append(label)\n",
    "#     tests.append(observed)\n",
    "\n",
    "# print(metrics.confusion_matrix(labels, tests))\n",
    "\n",
    "# confusion_matrix(X_test,y_test)\n",
    "\n",
    "# from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
