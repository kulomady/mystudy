{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spacy.lang.id import Indonesian\n",
    "from spacy.lang.id.stop_words import STOP_WORDS\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Indonesian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Tagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jakarta, Di jejaring sosial, banyak beredar in...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Isu bahwa ikan lele mengandung sel kanker di j...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bagi penikmat kuliner dengan bahan dasar ikan ...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ikan lele merupakan salah satu makanan favorit...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ikan lele merupakan bahan makanan yang cukup p...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SURABAYA, KOMPAS.com - \"Dalam sesuap daging ik...</td>\n",
       "      <td>hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bahaya Mengkonsumsi Ikan Lele Yang Mengandung ...</td>\n",
       "      <td>hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Di jejaring sosial, banyak beredar informasi y...</td>\n",
       "      <td>hoax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Jakarta, Sebuah artikel yang cukup viral di in...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Pada dasarnya tidak ada makanan yang membawa s...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           Articles Tagging\n",
       "0   1  Jakarta, Di jejaring sosial, banyak beredar in...   valid\n",
       "1   2  Isu bahwa ikan lele mengandung sel kanker di j...   valid\n",
       "2   3  Bagi penikmat kuliner dengan bahan dasar ikan ...   valid\n",
       "3   4  Ikan lele merupakan salah satu makanan favorit...   valid\n",
       "4   5  Ikan lele merupakan bahan makanan yang cukup p...   valid\n",
       "5   6  SURABAYA, KOMPAS.com - \"Dalam sesuap daging ik...    hoax\n",
       "6   7  Bahaya Mengkonsumsi Ikan Lele Yang Mengandung ...    hoax\n",
       "7   8  Di jejaring sosial, banyak beredar informasi y...    hoax\n",
       "8   9  Jakarta, Sebuah artikel yang cukup viral di in...   valid\n",
       "9  10  Pada dasarnya tidak ada makanan yang membawa s...   valid"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"News-Articles-Dataset.xls\", sheet_name = \"berita\", na_values = ' ')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Articles</th>\n",
       "      <th>Tagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jakarta, Di jejaring sosial, banyak beredar in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Isu bahwa ikan lele mengandung sel kanker di j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bagi penikmat kuliner dengan bahan dasar ikan ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ikan lele merupakan salah satu makanan favorit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ikan lele merupakan bahan makanan yang cukup p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SURABAYA, KOMPAS.com - \"Dalam sesuap daging ik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bahaya Mengkonsumsi Ikan Lele Yang Mengandung ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Di jejaring sosial, banyak beredar informasi y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Jakarta, Sebuah artikel yang cukup viral di in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Pada dasarnya tidak ada makanan yang membawa s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           Articles  Tagging\n",
       "0   1  Jakarta, Di jejaring sosial, banyak beredar in...        1\n",
       "1   2  Isu bahwa ikan lele mengandung sel kanker di j...        1\n",
       "2   3  Bagi penikmat kuliner dengan bahan dasar ikan ...        1\n",
       "3   4  Ikan lele merupakan salah satu makanan favorit...        1\n",
       "4   5  Ikan lele merupakan bahan makanan yang cukup p...        1\n",
       "5   6  SURABAYA, KOMPAS.com - \"Dalam sesuap daging ik...        0\n",
       "6   7  Bahaya Mengkonsumsi Ikan Lele Yang Mengandung ...        0\n",
       "7   8  Di jejaring sosial, banyak beredar informasi y...        0\n",
       "8   9  Jakarta, Sebuah artikel yang cukup viral di in...        1\n",
       "9  10  Pada dasarnya tidak ada makanan yang membawa s...        1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace tagging with numeric value\n",
    "# 1 for valid article \n",
    "# 0 for hoax article\n",
    "df.Tagging.replace(['valid', 'hoax'], [1, 0], inplace= True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sebutlah',\n",
       " 'seluruhnya',\n",
       " 'jangankan',\n",
       " 'datang',\n",
       " 'sela',\n",
       " 'sebagainya',\n",
       " 'waktunya',\n",
       " 'seketika',\n",
       " 'tiga',\n",
       " 'mendapat',\n",
       " 'ataupun',\n",
       " 'biasa',\n",
       " 'seorang',\n",
       " 'khususnya',\n",
       " 'sepertinya',\n",
       " 'bermacam',\n",
       " 'toh',\n",
       " 'manalagi',\n",
       " 'tuturnya',\n",
       " 'bersiap',\n",
       " 'dilihat',\n",
       " 'mempersiapkan',\n",
       " 'bakalan',\n",
       " 'bawah',\n",
       " 'dari',\n",
       " 'mereka',\n",
       " 'jadi',\n",
       " 'meminta',\n",
       " 'bermaksud',\n",
       " 'janganlah',\n",
       " 'berapa',\n",
       " 'jumlah',\n",
       " 'bermula',\n",
       " 'sebutnya',\n",
       " 'dimintai',\n",
       " 'siapakah',\n",
       " 'bertanya-tanya',\n",
       " 'sendirian',\n",
       " 'pada',\n",
       " 'sejak',\n",
       " 'siap',\n",
       " 'sekaligus',\n",
       " 'juga',\n",
       " 'mengibaratkannya',\n",
       " 'tandas',\n",
       " 'malah',\n",
       " 'selaku',\n",
       " 'tersampaikan',\n",
       " 'depan',\n",
       " 'semaunya',\n",
       " 'tidaklah',\n",
       " 'mendatang',\n",
       " 'segala',\n",
       " 'tampak',\n",
       " 'kepada',\n",
       " 'cuma',\n",
       " 'dimulailah',\n",
       " 'semata',\n",
       " 'sebelumnya',\n",
       " 'ditunjuk',\n",
       " 'masing',\n",
       " 'menunjuknya',\n",
       " 'bermacam-macam',\n",
       " 'jawaban',\n",
       " 'itulah',\n",
       " 'perlunya',\n",
       " 'kemudian',\n",
       " 'kala',\n",
       " 'setiap',\n",
       " 'sejumlah',\n",
       " 'selama',\n",
       " 'sempat',\n",
       " 'kamulah',\n",
       " 'kalaupun',\n",
       " 'kitalah',\n",
       " 'berupa',\n",
       " 'benarlah',\n",
       " 'rupanya',\n",
       " 'pertanyakan',\n",
       " 'daripada',\n",
       " 'sedikitnya',\n",
       " 'dimulainya',\n",
       " 'macam',\n",
       " 'diperlukannya',\n",
       " 'diingatkan',\n",
       " 'berujar',\n",
       " 'tadi',\n",
       " 'wong',\n",
       " 'melalui',\n",
       " 'dimaksud',\n",
       " 'semampu',\n",
       " 'bisakah',\n",
       " 'sini',\n",
       " 'berikan',\n",
       " 'tanya',\n",
       " 'beginian',\n",
       " 'para',\n",
       " 'sekitarnya',\n",
       " 'apalagi',\n",
       " 'semisal',\n",
       " 'suatu',\n",
       " 'termasuk',\n",
       " 'sendiri',\n",
       " 'menaiki',\n",
       " 'kamilah',\n",
       " 'ibaratnya',\n",
       " 'diinginkan',\n",
       " 'agaknya',\n",
       " 'dini',\n",
       " 'akhiri',\n",
       " 'diminta',\n",
       " 'didapat',\n",
       " 'sebelum',\n",
       " 'supaya',\n",
       " 'hendaknya',\n",
       " 'dahulu',\n",
       " 'mulailah',\n",
       " 'ia',\n",
       " 'ke',\n",
       " 'begitukah',\n",
       " 'tak',\n",
       " 'dua',\n",
       " 'kalaulah',\n",
       " 'berjumlah',\n",
       " 'keinginan',\n",
       " 'sebaliknya',\n",
       " 'disebutkannya',\n",
       " 'serupa',\n",
       " 'dirinya',\n",
       " 'diucapkannya',\n",
       " 'semata-mata',\n",
       " 'berawal',\n",
       " 'sekiranya',\n",
       " 'sama',\n",
       " 'ada',\n",
       " 'kurang',\n",
       " 'lanjut',\n",
       " 'bukanlah',\n",
       " 'dituturkan',\n",
       " 'kepadanya',\n",
       " 'pihak',\n",
       " 'mendatangi',\n",
       " 'digunakan',\n",
       " 'meskipun',\n",
       " 'dimisalkan',\n",
       " 'menegaskan',\n",
       " 'lamanya',\n",
       " 'menanyai',\n",
       " 'lama',\n",
       " 'diucapkan',\n",
       " 'bekerja',\n",
       " 'demikian',\n",
       " 'dijelaskan',\n",
       " 'sedang',\n",
       " 'bila',\n",
       " 'gunakan',\n",
       " 'tunjuk',\n",
       " 'dipertanyakan',\n",
       " 'apatah',\n",
       " 'dipersoalkan',\n",
       " 'keseluruhan',\n",
       " 'amat',\n",
       " 'sesuatunya',\n",
       " 'jadilah',\n",
       " 'ucapnya',\n",
       " 'begitu',\n",
       " 'bertutur',\n",
       " 'menggunakan',\n",
       " 'berdatangan',\n",
       " 'berkenaan',\n",
       " 'benar',\n",
       " 'itu',\n",
       " 'adalah',\n",
       " 'memastikan',\n",
       " 'kira',\n",
       " 'dipergunakan',\n",
       " 'percuma',\n",
       " 'selalu',\n",
       " 'tiba-tiba',\n",
       " 'menantikan',\n",
       " 'dipunyai',\n",
       " 'beri',\n",
       " 'hari',\n",
       " 'bahwa',\n",
       " 'kami',\n",
       " 'nyaris',\n",
       " 'sekalipun',\n",
       " 'seperti',\n",
       " 'walaupun',\n",
       " 'antara',\n",
       " 'tahun',\n",
       " 'dijawab',\n",
       " 'dulu',\n",
       " 'memberi',\n",
       " 'diberikan',\n",
       " 'karena',\n",
       " 'menuju',\n",
       " 'naik',\n",
       " 'baru',\n",
       " 'berbagai',\n",
       " 'menuturkan',\n",
       " 'belumlah',\n",
       " 'masih',\n",
       " 'beberapa',\n",
       " 'dikatakannya',\n",
       " 'mengerjakan',\n",
       " 'sebetulnya',\n",
       " 'bilakah',\n",
       " 'demikianlah',\n",
       " 'sebisanya',\n",
       " 'segalanya',\n",
       " 'masihkah',\n",
       " 'yaitu',\n",
       " 'bagaimanakah',\n",
       " 'ingat-ingat',\n",
       " 'balik',\n",
       " 'dikatakan',\n",
       " 'tetap',\n",
       " 'mau',\n",
       " 'usah',\n",
       " 'kira-kira',\n",
       " 'mempergunakan',\n",
       " 'pernah',\n",
       " 'terkira',\n",
       " 'empat',\n",
       " 'diperlihatkan',\n",
       " 'panjang',\n",
       " 'sebegitu',\n",
       " 'wahai',\n",
       " 'dengan',\n",
       " 'amatlah',\n",
       " 'sekarang',\n",
       " 'se',\n",
       " 'setempat',\n",
       " 'mengingat',\n",
       " 'berapapun',\n",
       " 'berlebihan',\n",
       " 'ucap',\n",
       " 'sekurang-kurangnya',\n",
       " 'nantinya',\n",
       " 'awal',\n",
       " 'menjelaskan',\n",
       " 'saat',\n",
       " 'makin',\n",
       " 'serta',\n",
       " 'tutur',\n",
       " 'dekat',\n",
       " 'dilalui',\n",
       " 'ibarat',\n",
       " 'seberapa',\n",
       " 'terasa',\n",
       " 'memintakan',\n",
       " 'dapat',\n",
       " 'sesudahnya',\n",
       " 'hendaklah',\n",
       " 'lainnya',\n",
       " 'adanya',\n",
       " 'diakhiri',\n",
       " 'mengingatkan',\n",
       " 'pak',\n",
       " 'jadinya',\n",
       " 'bersiap-siap',\n",
       " 'bisa',\n",
       " 'mengucapkannya',\n",
       " 'semua',\n",
       " 'mirip',\n",
       " 'rata',\n",
       " 'sama-sama',\n",
       " 'disebut',\n",
       " 'kan',\n",
       " 'paling',\n",
       " 'penting',\n",
       " 'usai',\n",
       " 'tegasnya',\n",
       " 'hal',\n",
       " 'sepanjang',\n",
       " 'setengah',\n",
       " 'menjadi',\n",
       " 'jawabnya',\n",
       " 'pertama-tama',\n",
       " 'ditunjukkan',\n",
       " 'membuat',\n",
       " 'seusai',\n",
       " 'tempat',\n",
       " 'tengah',\n",
       " 'sekitar',\n",
       " 'jikalau',\n",
       " 'kemungkinannya',\n",
       " 'mengakhiri',\n",
       " 'beginilah',\n",
       " 'kasus',\n",
       " 'setinggi',\n",
       " 'kenapa',\n",
       " 'mampukah',\n",
       " 'apa',\n",
       " 'misal',\n",
       " 'sinilah',\n",
       " 'kelihatan',\n",
       " 'melihat',\n",
       " 'wah',\n",
       " 'berakhirnya',\n",
       " 'diakhirinya',\n",
       " 'tambah',\n",
       " 'jawab',\n",
       " 'secukupnya',\n",
       " 'bertanya',\n",
       " 'lewat',\n",
       " 'diri',\n",
       " 'sebut',\n",
       " 'demi',\n",
       " 'diperlukan',\n",
       " 'sesaat',\n",
       " 'disini',\n",
       " 'telah',\n",
       " 'bukankah',\n",
       " 'jelasnya',\n",
       " 'sebenarnya',\n",
       " 'dibuatnya',\n",
       " 'kinilah',\n",
       " 'terhadapnya',\n",
       " 'kedua',\n",
       " 'bagaimanapun',\n",
       " 'baik',\n",
       " 'melihatnya',\n",
       " 'dong',\n",
       " 'setibanya',\n",
       " 'masalahnya',\n",
       " 'oleh',\n",
       " 'memerlukan',\n",
       " 'siapa',\n",
       " 'berikutnya',\n",
       " 'diungkapkan',\n",
       " 'mengetahui',\n",
       " 'seterusnya',\n",
       " 'ditegaskan',\n",
       " 'diibaratkannya',\n",
       " 'dialah',\n",
       " 'ditambahkan',\n",
       " 'ibaratkan',\n",
       " 'merasa',\n",
       " 'bahwasanya',\n",
       " 'apabila',\n",
       " 'tegas',\n",
       " 'menunjukkan',\n",
       " 'seringnya',\n",
       " 'sewaktu',\n",
       " 'hanya',\n",
       " 'teringat',\n",
       " 'ataukah',\n",
       " 'keseluruhannya',\n",
       " 'sangatlah',\n",
       " 'harusnya',\n",
       " 'sering',\n",
       " 'sebesar',\n",
       " 'perlukah',\n",
       " 'satu',\n",
       " 'kok',\n",
       " 'bahkan',\n",
       " 'disampaikan',\n",
       " 'ditujukan',\n",
       " 'bulan',\n",
       " 'sepantasnyalah',\n",
       " 'lebih',\n",
       " 'setidak-tidaknya',\n",
       " 'lain',\n",
       " 'punya',\n",
       " 'tadinya',\n",
       " 'semisalnya',\n",
       " 'memperlihatkan',\n",
       " 'ujarnya',\n",
       " 'bagi',\n",
       " 'mengenai',\n",
       " 'dan',\n",
       " 'kelihatannya',\n",
       " 'ditunjuki',\n",
       " 'kemungkinan',\n",
       " 'agar',\n",
       " 'sesampai',\n",
       " 'pastilah',\n",
       " 'tinggi',\n",
       " 'terhadap',\n",
       " 'diantara',\n",
       " 'inilah',\n",
       " 'pun',\n",
       " 'begitulah',\n",
       " 'sekadarnya',\n",
       " 'bagai',\n",
       " 'begitupun',\n",
       " 'bukannya',\n",
       " 'menanti',\n",
       " 'ditandaskan',\n",
       " 'berkali-kali',\n",
       " 'kesampaian',\n",
       " 'semampunya',\n",
       " 'soalnya',\n",
       " 'menginginkan',\n",
       " 'inikah',\n",
       " 'katakanlah',\n",
       " 'belakangan',\n",
       " 'mendatangkan',\n",
       " 'dipastikan',\n",
       " 'antar',\n",
       " 'maka',\n",
       " 'cara',\n",
       " 'semakin',\n",
       " 'aku',\n",
       " 'mengucapkan',\n",
       " 'kalau',\n",
       " 'sudah',\n",
       " 'diperbuatnya',\n",
       " 'tentu',\n",
       " 'berakhirlah',\n",
       " 'diingat',\n",
       " 'menjawab',\n",
       " 'bolehlah',\n",
       " 'mengungkapkan',\n",
       " 'berlalu',\n",
       " 'mula',\n",
       " 'boleh',\n",
       " 'ditunjuknya',\n",
       " 'sebaiknya',\n",
       " 'menanyakan',\n",
       " 'tahu',\n",
       " 'tidak',\n",
       " 'tentulah',\n",
       " 'adapun',\n",
       " 'pertanyaan',\n",
       " 'hampir',\n",
       " 'berarti',\n",
       " 'maupun',\n",
       " 'keadaan',\n",
       " 'ini',\n",
       " 'masing-masing',\n",
       " 'sebagai',\n",
       " 'sebuah',\n",
       " 'tapi',\n",
       " 'memulai',\n",
       " 'dimaksudkannya',\n",
       " 'saya',\n",
       " 'sebegini',\n",
       " 'seluruh',\n",
       " 'tetapi',\n",
       " 'keluar',\n",
       " 'ujar',\n",
       " 'asal',\n",
       " 'sesegera',\n",
       " 'pentingnya',\n",
       " 'tentunya',\n",
       " 'luar',\n",
       " 'setidaknya',\n",
       " 'hendak',\n",
       " 'menandaskan',\n",
       " 'segera',\n",
       " 'betulkah',\n",
       " 'yakni',\n",
       " 'andalah',\n",
       " 'anda',\n",
       " 'dituturkannya',\n",
       " 'didatangkan',\n",
       " 'betul',\n",
       " 'ungkapnya',\n",
       " 'guna',\n",
       " 'sudahkah',\n",
       " 'sebaik',\n",
       " 'siapapun',\n",
       " 'dijelaskannya',\n",
       " 'memungkinkan',\n",
       " 'padahal',\n",
       " 'lah',\n",
       " 'sejauh',\n",
       " 'dia',\n",
       " 'berkehendak',\n",
       " 'berakhir',\n",
       " 'dikarenakan',\n",
       " 'per',\n",
       " 'kapankah',\n",
       " 'terjadi',\n",
       " 'ibu',\n",
       " 'tidakkah',\n",
       " 'lalu',\n",
       " 'caranya',\n",
       " 'seseorang',\n",
       " 'terjadilah',\n",
       " 'sampai',\n",
       " 'sesuatu',\n",
       " 'mengatakannya',\n",
       " 'ditanya',\n",
       " 'ikut',\n",
       " 'jelaslah',\n",
       " 'diketahuinya',\n",
       " 'ditanyakan',\n",
       " 'sekali',\n",
       " 'nyatanya',\n",
       " 'sesekali',\n",
       " 'terlebih',\n",
       " 'menyeluruh',\n",
       " 'ungkap',\n",
       " 'seharusnya',\n",
       " 'tersebut',\n",
       " 'melainkan',\n",
       " 'terlalu',\n",
       " 'jumlahnya',\n",
       " 'terjadinya',\n",
       " 'bakal',\n",
       " 'sekurangnya',\n",
       " 'waktu',\n",
       " 'saling',\n",
       " 'sekalian',\n",
       " 'katanya',\n",
       " 'tampaknya',\n",
       " 'berapakah',\n",
       " 'diperkirakan',\n",
       " 'benarkah',\n",
       " 'jauh',\n",
       " 'sajalah',\n",
       " 'mana',\n",
       " 'belum',\n",
       " 'secara',\n",
       " 'sekadar',\n",
       " 'menyangkut',\n",
       " 'kata',\n",
       " 'keterlaluan',\n",
       " 'saja',\n",
       " 'sangat',\n",
       " 'sampaikan',\n",
       " 'begini',\n",
       " 'bukan',\n",
       " 'pertama',\n",
       " 'mempersoalkan',\n",
       " 'merupakan',\n",
       " 'kapanpun',\n",
       " 'beginikah',\n",
       " 'ditanyai',\n",
       " 'ingat',\n",
       " 'berapalah',\n",
       " 'sebabnya',\n",
       " 'umum',\n",
       " 'jelas',\n",
       " 'berlangsung',\n",
       " 'cukup',\n",
       " 'apaan',\n",
       " 'jika',\n",
       " 'pasti',\n",
       " 'terutama',\n",
       " 'kita',\n",
       " 'menyebutkan',\n",
       " 'yakin',\n",
       " 'sekecil',\n",
       " 'disebutkan',\n",
       " 'padanya',\n",
       " 'berada',\n",
       " 'masa',\n",
       " 'perlu',\n",
       " 'tanyakan',\n",
       " 'ketika',\n",
       " 'berlainan',\n",
       " 'merekalah',\n",
       " 'diperbuat',\n",
       " 'mengibaratkan',\n",
       " 'sudahlah',\n",
       " 'sayalah',\n",
       " 'menunjuki',\n",
       " 'semacam',\n",
       " 'menunjuk',\n",
       " 'biasanya',\n",
       " 'inginkan',\n",
       " 'tertuju',\n",
       " 'pihaknya',\n",
       " 'dimulai',\n",
       " 'memperbuat',\n",
       " 'minta',\n",
       " 'tambahnya',\n",
       " 'di',\n",
       " 'disinilah',\n",
       " 'manakala',\n",
       " 'dibuat',\n",
       " 'awalnya',\n",
       " 'nanti',\n",
       " 'diketahui',\n",
       " 'diibaratkan',\n",
       " 'memang',\n",
       " 'bagaikan',\n",
       " 'mulai',\n",
       " 'keduanya',\n",
       " 'asalkan',\n",
       " 'bersama-sama',\n",
       " 'mengapa',\n",
       " 'mungkinkah',\n",
       " 'kecil',\n",
       " 'pula',\n",
       " 'seenaknya',\n",
       " 'meski',\n",
       " 'terdapat',\n",
       " 'mendapatkan',\n",
       " 'sambil',\n",
       " 'lagian',\n",
       " 'lanjutnya',\n",
       " 'malahan',\n",
       " 'tepat',\n",
       " 'semula',\n",
       " 'turut',\n",
       " 'terbanyak',\n",
       " 'umumnya',\n",
       " 'diantaranya',\n",
       " 'akhirnya',\n",
       " 'namun',\n",
       " 'kelamaan',\n",
       " 'setelah',\n",
       " 'waduh',\n",
       " 'buat',\n",
       " 'walau',\n",
       " 'sejenak',\n",
       " 'dikira',\n",
       " 'akhir',\n",
       " 'seperlunya',\n",
       " 'berturut-turut',\n",
       " 'sepantasnya',\n",
       " 'sana',\n",
       " 'makanya',\n",
       " 'sebagian',\n",
       " 'kalian',\n",
       " 'sesama',\n",
       " 'diberikannya',\n",
       " 'sedikit',\n",
       " 'itukah',\n",
       " 'selama-lamanya',\n",
       " 'saatnya',\n",
       " 'tanyanya',\n",
       " 'selain',\n",
       " 'misalkan',\n",
       " 'dalam',\n",
       " 'olehnya',\n",
       " 'semuanya',\n",
       " 'kini',\n",
       " 'lagi',\n",
       " 'sehingga',\n",
       " 'cukupkah',\n",
       " 'sedemikian',\n",
       " 'bagian',\n",
       " 'mempertanyakan',\n",
       " 'akan',\n",
       " 'menyatakan',\n",
       " 'kelima',\n",
       " 'dimaksudnya',\n",
       " 'menanya',\n",
       " 'bersama',\n",
       " 'tanpa',\n",
       " 'hingga',\n",
       " 'ingin',\n",
       " 'mengatakan',\n",
       " 'sebagaimana',\n",
       " 'seingat',\n",
       " 'berkata',\n",
       " 'atas',\n",
       " 'yang',\n",
       " 'melakukan',\n",
       " 'terakhir',\n",
       " 'selanjutnya',\n",
       " 'dilakukan',\n",
       " 'dikerjakan',\n",
       " 'bolehkah',\n",
       " 'teringat-ingat',\n",
       " 'kamu',\n",
       " 'memperkirakan',\n",
       " 'sekali-kali',\n",
       " 'enggaknya',\n",
       " 'kembali',\n",
       " 'persoalan',\n",
       " 'berturut',\n",
       " 'atau',\n",
       " 'sedangkan',\n",
       " 'terdahulu',\n",
       " 'akankah',\n",
       " 'menambahkan',\n",
       " 'mungkin',\n",
       " 'menyiapkan',\n",
       " 'bagaimana',\n",
       " 'jelaskan',\n",
       " 'tersebutlah',\n",
       " 'lima',\n",
       " 'bung',\n",
       " 'terdiri',\n",
       " 'memisalkan',\n",
       " 'meyakini',\n",
       " 'sendirinya',\n",
       " 'pantas',\n",
       " 'menurut',\n",
       " 'artinya',\n",
       " 'sebab',\n",
       " 'enggak',\n",
       " 'memberikan',\n",
       " 'terus',\n",
       " 'entah',\n",
       " 'bapak',\n",
       " 'haruslah',\n",
       " 'berikut',\n",
       " 'mengira',\n",
       " 'mempunyai',\n",
       " 'semasih',\n",
       " 'seolah',\n",
       " 'diberi',\n",
       " 'sementara',\n",
       " 'untuk',\n",
       " 'ditunjukkannya',\n",
       " 'menyampaikan',\n",
       " 'sebaik-baiknya',\n",
       " 'dimaksudkan',\n",
       " 'memihak',\n",
       " 'besar',\n",
       " 'entahlah',\n",
       " 'sesudah',\n",
       " 'menghendaki',\n",
       " 'selamanya',\n",
       " 'rasanya',\n",
       " 'berkeinginan',\n",
       " 'karenanya',\n",
       " 'dimungkinkan',\n",
       " 'akulah',\n",
       " 'ialah',\n",
       " 'jangan',\n",
       " 'katakan',\n",
       " 'sampai-sampai',\n",
       " 'tandasnya',\n",
       " 'agak',\n",
       " 'kebetulan',\n",
       " 'sepihak',\n",
       " 'sebanyak',\n",
       " 'tentang',\n",
       " 'inginkah',\n",
       " 'apakah',\n",
       " 'kapan',\n",
       " 'soal',\n",
       " 'hanyalah',\n",
       " 'tertentu',\n",
       " 'harus',\n",
       " 'meyakinkan',\n",
       " 'cukuplah',\n",
       " 'justru',\n",
       " 'antaranya',\n",
       " 'masalah',\n",
       " 'mulanya',\n",
       " 'setiba',\n",
       " 'mampu',\n",
       " 'rasa',\n",
       " 'pukul',\n",
       " 'seolah-olah',\n",
       " 'kiranya',\n",
       " 'belakang',\n",
       " 'nah',\n",
       " 'tiba',\n",
       " 'terlihat',\n",
       " 'tiap',\n",
       " 'misalnya',\n",
       " 'ternyata',\n",
       " 'menanti-nanti',\n",
       " 'semasa',\n",
       " 'banyak']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jakarta, Di jejaring sosial, banyak beredar informasi yang menyebut lele sebagai ikan paling jorok. Dalam sesuap daging ikan lele, terkandung 3000 sel kanker. Benarkah?\\nJulukan sebagai ikan paling jorok merujuk pada sifat lele yang doyan mengonsumsi segala jenis limbah di perairan. Bahkan sebuah artikel yang cukup viral di internet menyebutkan kotoran manusia juga dijadikan pakan pada sebuah budidaya lele di Kota Haikou, China.\\nSementara itu di habitat aslinya, lele atau catfish juga dikenal sebagai spesies ikan yang sangat tangguh. Ikan ini dilengkapi alat pernapasan tambahan berupa labirin, sehingga mampu bertahan hidup dalam kondisi perairan berlumpur atau bahkan tercemar. Agaknya, fakta inilah yang memunculkan dugaan soal akumulasi racun karsinogen (penyebab kanker) di tubuh ikan lele.\\nUntungnya, ikan lele yang beredar di pasaran bukan berasal dari alam liar. Lele banyak dibudidayakan di kolam-kolam, yang mestinya bisa dikendalikan agar bebas dari pencemaran. Pakan yang diberikan juga bisa dipilih, tidak harus mengandalkan limbah.\\nYang pasti, popularitas ikan bersungut ini tidak pernah pudar, bahkan terus meningkat. Data Kementerian Kelautan dan Perikanan (KKP) menyebut produksi lele pada 2013 mencapai 543,461 ton, meningkat dari 441,217 ton pada 2012 dan 337,577 ton pada 2011.\\nKonsumsi ikan lele menurut Badan Pusat Statistik (BPS) tercatat 29,98 kg/kapita/tahun, naik dari 22,58 kg/kapita/tahun pada 2004. Di Jakarta, tak kurang dari 6000 lapak pecel lele telah terdaftar di Asosiasi Pedagang Kaki Lima Indonesia (APKLI).\\nSoal kandungan nutrisi, tak bisa dipungkiri bahwa lele adalah sumber protein berharga yang murah meriah. Fakta bahwa ikan lele juga rendah kolesterol sepertinya bakal menenggelamkan tudingan bahwa lele bisa memicu kanker. \"Saat ini belum ada penelitian yang menyatakan jika memakan lele dapat memicu kanker,\" tegas dr Dradjat R Suardi, SpB(K)Onk, ahli kanker dari Perhimpunan Onkologi Indonesia saat dihubungi detikHealth, Jumat (23/10/2015).\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleArticle = df['Articles'].values[0]\n",
    "sampleArticle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jakarta Lemma => Jakarta\n",
      ", Lemma => ,\n",
      "Di Lemma => Di\n",
      "jejaring Lemma => jejaring\n",
      "sosial Lemma => sosial\n",
      ", Lemma => ,\n",
      "banyak Lemma => banyak\n",
      "beredar Lemma => edar\n",
      "informasi Lemma => informasi\n",
      "yang Lemma => yang\n",
      "menyebut Lemma => sebut\n",
      "lele Lemma => lele\n",
      "sebagai Lemma => bagai\n",
      "ikan Lemma => ikan\n",
      "paling Lemma => paling\n",
      "jorok Lemma => jorok\n",
      ". Lemma => .\n",
      "Dalam Lemma => Dalam\n",
      "sesuap Lemma => suap\n",
      "daging Lemma => daging\n",
      "ikan Lemma => ikan\n",
      "lele Lemma => lele\n",
      ", Lemma => ,\n",
      "terkandung Lemma => kandung\n",
      "3000 Lemma => 3000\n",
      "sel Lemma => sel\n",
      "kanker Lemma => kanker\n",
      ". Lemma => .\n",
      "Benarkah Lemma => Benarkah\n",
      "? Lemma => ?\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Julukan Lemma => Julukan\n",
      "sebagai Lemma => bagai\n",
      "ikan Lemma => ikan\n",
      "paling Lemma => paling\n",
      "jorok Lemma => jorok\n",
      "merujuk Lemma => rujuk\n",
      "pada Lemma => pada\n",
      "sifat Lemma => sifat\n",
      "lele Lemma => lele\n",
      "yang Lemma => yang\n",
      "doyan Lemma => doyan\n",
      "mengonsumsi Lemma => konsumsi\n",
      "segala Lemma => segala\n",
      "jenis Lemma => jenis\n",
      "limbah Lemma => limbah\n",
      "di Lemma => di\n",
      "perairan Lemma => air\n",
      ". Lemma => .\n",
      "Bahkan Lemma => Bahkan\n",
      "sebuah Lemma => sebuah\n",
      "artikel Lemma => artikel\n",
      "yang Lemma => yang\n",
      "cukup Lemma => cukup\n",
      "viral Lemma => viral\n",
      "di Lemma => di\n",
      "internet Lemma => internet\n",
      "menyebutkan Lemma => sebut\n",
      "kotoran Lemma => kotor\n",
      "manusia Lemma => manusia\n",
      "juga Lemma => juga\n",
      "dijadikan Lemma => dijadikan\n",
      "pakan Lemma => pakan\n",
      "pada Lemma => pada\n",
      "sebuah Lemma => sebuah\n",
      "budidaya Lemma => budidaya\n",
      "lele Lemma => lele\n",
      "di Lemma => di\n",
      "Kota Lemma => Kota\n",
      "Haikou Lemma => Haikou\n",
      ", Lemma => ,\n",
      "China Lemma => China\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Sementara Lemma => Sementara\n",
      "itu Lemma => itu\n",
      "di Lemma => di\n",
      "habitat Lemma => habitat\n",
      "aslinya Lemma => aslinya\n",
      ", Lemma => ,\n",
      "lele Lemma => lele\n",
      "atau Lemma => atau\n",
      "catfish Lemma => catfish\n",
      "juga Lemma => juga\n",
      "dikenal Lemma => dikenal\n",
      "sebagai Lemma => bagai\n",
      "spesies Lemma => spesies\n",
      "ikan Lemma => ikan\n",
      "yang Lemma => yang\n",
      "sangat Lemma => sangat\n",
      "tangguh Lemma => tangguh\n",
      ". Lemma => .\n",
      "Ikan Lemma => Ikan\n",
      "ini Lemma => ini\n",
      "dilengkapi Lemma => dilengkapi\n",
      "alat Lemma => alat\n",
      "pernapasan Lemma => napas\n",
      "tambahan Lemma => tambah\n",
      "berupa Lemma => rupa\n",
      "labirin Lemma => labirin\n",
      ", Lemma => ,\n",
      "sehingga Lemma => sehingga\n",
      "mampu Lemma => mampu\n",
      "bertahan Lemma => tahan\n",
      "hidup Lemma => hidup\n",
      "dalam Lemma => dalam\n",
      "kondisi Lemma => kondisi\n",
      "perairan Lemma => air\n",
      "berlumpur Lemma => lumpur\n",
      "atau Lemma => atau\n",
      "bahkan Lemma => bahkan\n",
      "tercemar Lemma => cemar\n",
      ". Lemma => .\n",
      "Agaknya Lemma => Agaknya\n",
      ", Lemma => ,\n",
      "fakta Lemma => fakta\n",
      "inilah Lemma => inilah\n",
      "yang Lemma => yang\n",
      "memunculkan Lemma => muncul\n",
      "dugaan Lemma => duga\n",
      "soal Lemma => soal\n",
      "akumulasi Lemma => akumulasi\n",
      "racun Lemma => racun\n",
      "karsinogen Lemma => karsinogen\n",
      "( Lemma => (\n",
      "penyebab Lemma => sebab\n",
      "kanker Lemma => kanker\n",
      ") Lemma => )\n",
      "di Lemma => di\n",
      "tubuh Lemma => tubuh\n",
      "ikan Lemma => ikan\n",
      "lele Lemma => lele\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Untungnya Lemma => Untungnya\n",
      ", Lemma => ,\n",
      "ikan Lemma => ikan\n",
      "lele Lemma => lele\n",
      "yang Lemma => yang\n",
      "beredar Lemma => edar\n",
      "di Lemma => di\n",
      "pasaran Lemma => pasar\n",
      "bukan Lemma => bukan\n",
      "berasal Lemma => asal\n",
      "dari Lemma => dari\n",
      "alam Lemma => alam\n",
      "liar Lemma => liar\n",
      ". Lemma => .\n",
      "Lele Lemma => Lele\n",
      "banyak Lemma => banyak\n",
      "dibudidayakan Lemma => dibudidayakan\n",
      "di Lemma => di\n",
      "kolam Lemma => kolam\n",
      "- Lemma => -\n",
      "kolam Lemma => kolam\n",
      ", Lemma => ,\n",
      "yang Lemma => yang\n",
      "mestinya Lemma => mestinya\n",
      "bisa Lemma => bisa\n",
      "dikendalikan Lemma => dikendalikan\n",
      "agar Lemma => agar\n",
      "bebas Lemma => bebas\n",
      "dari Lemma => dari\n",
      "pencemaran Lemma => cemar\n",
      ". Lemma => .\n",
      "Pakan Lemma => Pakan\n",
      "yang Lemma => yang\n",
      "diberikan Lemma => diberikan\n",
      "juga Lemma => juga\n",
      "bisa Lemma => bisa\n",
      "dipilih Lemma => dipilih\n",
      ", Lemma => ,\n",
      "tidak Lemma => tidak\n",
      "harus Lemma => harus\n",
      "mengandalkan Lemma => andal\n",
      "limbah Lemma => limbah\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Yang Lemma => Yang\n",
      "pasti Lemma => pasti\n",
      ", Lemma => ,\n",
      "popularitas Lemma => popularitas\n",
      "ikan Lemma => ikan\n",
      "bersungut Lemma => sungut\n",
      "ini Lemma => ini\n",
      "tidak Lemma => tidak\n",
      "pernah Lemma => pernah\n",
      "pudar Lemma => pudar\n",
      ", Lemma => ,\n",
      "bahkan Lemma => bahkan\n",
      "terus Lemma => terus\n",
      "meningkat Lemma => tingkat\n",
      ". Lemma => .\n",
      "Data Lemma => Data\n",
      "Kementerian Lemma => Kementerian\n",
      "Kelautan Lemma => Kelautan\n",
      "dan Lemma => dan\n",
      "Perikanan Lemma => Perikanan\n",
      "( Lemma => (\n",
      "KKP Lemma => KKP\n",
      ") Lemma => )\n",
      "menyebut Lemma => sebut\n",
      "produksi Lemma => produksi\n",
      "lele Lemma => lele\n",
      "pada Lemma => pada\n",
      "2013 Lemma => 2013\n",
      "mencapai Lemma => capai\n",
      "543,461 Lemma => 543,461\n",
      "ton Lemma => ton\n",
      ", Lemma => ,\n",
      "meningkat Lemma => tingkat\n",
      "dari Lemma => dari\n",
      "441,217 Lemma => 441,217\n",
      "ton Lemma => ton\n",
      "pada Lemma => pada\n",
      "2012 Lemma => 2012\n",
      "dan Lemma => dan\n",
      "337,577 Lemma => 337,577\n",
      "ton Lemma => ton\n",
      "pada Lemma => pada\n",
      "2011 Lemma => 2011\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Konsumsi Lemma => Konsumsi\n",
      "ikan Lemma => ikan\n",
      "lele Lemma => lele\n",
      "menurut Lemma => turut\n",
      "Badan Lemma => Badan\n",
      "Pusat Lemma => Pusat\n",
      "Statistik Lemma => Statistik\n",
      "( Lemma => (\n",
      "BPS Lemma => BPS\n",
      ") Lemma => )\n",
      "tercatat Lemma => catat\n",
      "29,98 Lemma => 29,98\n",
      "kg Lemma => kg\n",
      "/ Lemma => /\n",
      "kapita Lemma => kapita\n",
      "/ Lemma => /\n",
      "tahun Lemma => tahun\n",
      ", Lemma => ,\n",
      "naik Lemma => naik\n",
      "dari Lemma => dari\n",
      "22,58 Lemma => 22,58\n",
      "kg Lemma => kg\n",
      "/ Lemma => /\n",
      "kapita Lemma => kapita\n",
      "/ Lemma => /\n",
      "tahun Lemma => tahun\n",
      "pada Lemma => pada\n",
      "2004 Lemma => 2004\n",
      ". Lemma => .\n",
      "Di Lemma => Di\n",
      "Jakarta Lemma => Jakarta\n",
      ", Lemma => ,\n",
      "tak Lemma => tak\n",
      "kurang Lemma => kurang\n",
      "dari Lemma => dari\n",
      "6000 Lemma => 6000\n",
      "lapak Lemma => lapak\n",
      "pecel Lemma => pecel\n",
      "lele Lemma => lele\n",
      "telah Lemma => telah\n",
      "terdaftar Lemma => daftar\n",
      "di Lemma => di\n",
      "Asosiasi Lemma => Asosiasi\n",
      "Pedagang Lemma => Pedagang\n",
      "Kaki Lemma => Kaki\n",
      "Lima Lemma => Lima\n",
      "Indonesia Lemma => Indonesia\n",
      "( Lemma => (\n",
      "APKLI Lemma => APKLI\n",
      ") Lemma => )\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n",
      "Soal Lemma => Soal\n",
      "kandungan Lemma => kandung\n",
      "nutrisi Lemma => nutrisi\n",
      ", Lemma => ,\n",
      "tak Lemma => tak\n",
      "bisa Lemma => bisa\n",
      "dipungkiri Lemma => dipungkiri\n",
      "bahwa Lemma => bahwa\n",
      "lele Lemma => lele\n",
      "adalah Lemma => adalah\n",
      "sumber Lemma => sumber\n",
      "protein Lemma => protein\n",
      "berharga Lemma => harga\n",
      "yang Lemma => yang\n",
      "murah Lemma => murah\n",
      "meriah Lemma => riah\n",
      ". Lemma => .\n",
      "Fakta Lemma => Fakta\n",
      "bahwa Lemma => bahwa\n",
      "ikan Lemma => ikan\n",
      "lele Lemma => lele\n",
      "juga Lemma => juga\n",
      "rendah Lemma => rendah\n",
      "kolesterol Lemma => kolesterol\n",
      "sepertinya Lemma => seperti\n",
      "bakal Lemma => bakal\n",
      "menenggelamkan Lemma => tenggelam\n",
      "tudingan Lemma => tuding\n",
      "bahwa Lemma => bahwa\n",
      "lele Lemma => lele\n",
      "bisa Lemma => bisa\n",
      "memicu Lemma => picu\n",
      "kanker Lemma => kanker\n",
      ". Lemma => .\n",
      "\" Lemma => \"\n",
      "Saat Lemma => Saat\n",
      "ini Lemma => ini\n",
      "belum Lemma => belum\n",
      "ada Lemma => ada\n",
      "penelitian Lemma => teliti\n",
      "yang Lemma => yang\n",
      "menyatakan Lemma => nyata\n",
      "jika Lemma => jika\n",
      "memakan Lemma => makan\n",
      "lele Lemma => lele\n",
      "dapat Lemma => dapat\n",
      "memicu Lemma => picu\n",
      "kanker Lemma => kanker\n",
      ", Lemma => ,\n",
      "\" Lemma => \"\n",
      "tegas Lemma => tegas\n",
      "dr Lemma => dr\n",
      "Dradjat Lemma => Dradjat\n",
      "R Lemma => R\n",
      "Suardi Lemma => Suardi\n",
      ", Lemma => ,\n",
      "SpB(K)Onk Lemma => SpB(K)Onk\n",
      ", Lemma => ,\n",
      "ahli Lemma => ahli\n",
      "kanker Lemma => kanker\n",
      "dari Lemma => dari\n",
      "Perhimpunan Lemma => Perhimpunan\n",
      "Onkologi Lemma => Onkologi\n",
      "Indonesia Lemma => Indonesia\n",
      "saat Lemma => saat\n",
      "dihubungi Lemma => dihubungi\n",
      "detikHealth Lemma => detikHealth\n",
      ", Lemma => ,\n",
      "Jumat Lemma => Jumat\n",
      "( Lemma => (\n",
      "23 Lemma => 23\n",
      "/ Lemma => /\n",
      "10 Lemma => 10\n",
      "/ Lemma => /\n",
      "2015 Lemma => 2015\n",
      ") Lemma => )\n",
      ". Lemma => .\n",
      "\n",
      " Lemma => \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "docx = nlp(sampleArticle)\n",
    "for word in docx: \n",
    "    print(word.text,\"Lemma =>\",word.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jakarta\n",
      "Di\n",
      "jejaring\n",
      "sosial\n",
      "beredar\n",
      "informasi\n",
      "menyebut\n",
      "lele\n",
      "ikan\n",
      "jorok\n",
      "Dalam\n",
      "sesuap\n",
      "daging\n",
      "ikan\n",
      "lele\n",
      "terkandung\n",
      "3000\n",
      "sel\n",
      "kanker\n",
      "Benarkah\n",
      "\n",
      "\n",
      "Julukan\n",
      "ikan\n",
      "jorok\n",
      "merujuk\n",
      "sifat\n",
      "lele\n",
      "doyan\n",
      "mengonsumsi\n",
      "jenis\n",
      "limbah\n",
      "perairan\n",
      "Bahkan\n",
      "artikel\n",
      "viral\n",
      "internet\n",
      "kotoran\n",
      "manusia\n",
      "dijadikan\n",
      "pakan\n",
      "budidaya\n",
      "lele\n",
      "Kota\n",
      "Haikou\n",
      "China\n",
      "\n",
      "\n",
      "Sementara\n",
      "habitat\n",
      "aslinya\n",
      "lele\n",
      "catfish\n",
      "dikenal\n",
      "spesies\n",
      "ikan\n",
      "tangguh\n",
      "Ikan\n",
      "dilengkapi\n",
      "alat\n",
      "pernapasan\n",
      "tambahan\n",
      "labirin\n",
      "bertahan\n",
      "hidup\n",
      "kondisi\n",
      "perairan\n",
      "berlumpur\n",
      "tercemar\n",
      "Agaknya\n",
      "fakta\n",
      "memunculkan\n",
      "dugaan\n",
      "akumulasi\n",
      "racun\n",
      "karsinogen\n",
      "penyebab\n",
      "kanker\n",
      "tubuh\n",
      "ikan\n",
      "lele\n",
      "\n",
      "\n",
      "Untungnya\n",
      "ikan\n",
      "lele\n",
      "beredar\n",
      "pasaran\n",
      "berasal\n",
      "alam\n",
      "liar\n",
      "Lele\n",
      "dibudidayakan\n",
      "kolam\n",
      "kolam\n",
      "mestinya\n",
      "dikendalikan\n",
      "bebas\n",
      "pencemaran\n",
      "Pakan\n",
      "dipilih\n",
      "mengandalkan\n",
      "limbah\n",
      "\n",
      "\n",
      "Yang\n",
      "popularitas\n",
      "ikan\n",
      "bersungut\n",
      "pudar\n",
      "meningkat\n",
      "Data\n",
      "Kementerian\n",
      "Kelautan\n",
      "Perikanan\n",
      "KKP\n",
      "menyebut\n",
      "produksi\n",
      "lele\n",
      "2013\n",
      "mencapai\n",
      "543,461\n",
      "ton\n",
      "meningkat\n",
      "441,217\n",
      "ton\n",
      "2012\n",
      "337,577\n",
      "ton\n",
      "2011\n",
      "\n",
      "\n",
      "Konsumsi\n",
      "ikan\n",
      "lele\n",
      "Badan\n",
      "Pusat\n",
      "Statistik\n",
      "BPS\n",
      "tercatat\n",
      "29,98\n",
      "kg\n",
      "kapita\n",
      "22,58\n",
      "kg\n",
      "kapita\n",
      "2004\n",
      "Di\n",
      "Jakarta\n",
      "6000\n",
      "lapak\n",
      "pecel\n",
      "lele\n",
      "terdaftar\n",
      "Asosiasi\n",
      "Pedagang\n",
      "Kaki\n",
      "Lima\n",
      "Indonesia\n",
      "APKLI\n",
      "\n",
      "\n",
      "Soal\n",
      "kandungan\n",
      "nutrisi\n",
      "dipungkiri\n",
      "lele\n",
      "sumber\n",
      "protein\n",
      "berharga\n",
      "murah\n",
      "meriah\n",
      "Fakta\n",
      "ikan\n",
      "lele\n",
      "rendah\n",
      "kolesterol\n",
      "menenggelamkan\n",
      "tudingan\n",
      "lele\n",
      "memicu\n",
      "kanker\n",
      "Saat\n",
      "penelitian\n",
      "memakan\n",
      "lele\n",
      "memicu\n",
      "kanker\n",
      "dr\n",
      "Dradjat\n",
      "R\n",
      "Suardi\n",
      "SpB(K)Onk\n",
      "ahli\n",
      "kanker\n",
      "Perhimpunan\n",
      "Onkologi\n",
      "Indonesia\n",
      "dihubungi\n",
      "detikHealth\n",
      "Jumat\n",
      "23\n",
      "10\n",
      "2015\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering out Stopwords and Punctuations\n",
    "for word in docx:\n",
    "    if word.is_stop == False and not word.is_punct:\n",
    "        if word.is_stop != True and not word.is_punct:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Jakarta,\n",
       " Di,\n",
       " jejaring,\n",
       " sosial,\n",
       " beredar,\n",
       " informasi,\n",
       " menyebut,\n",
       " lele,\n",
       " ikan,\n",
       " jorok,\n",
       " Dalam,\n",
       " sesuap,\n",
       " daging,\n",
       " ikan,\n",
       " lele,\n",
       " terkandung,\n",
       " 3000,\n",
       " sel,\n",
       " kanker,\n",
       " Benarkah,\n",
       " ,\n",
       " Julukan,\n",
       " ikan,\n",
       " jorok,\n",
       " merujuk,\n",
       " sifat,\n",
       " lele,\n",
       " doyan,\n",
       " mengonsumsi,\n",
       " jenis,\n",
       " limbah,\n",
       " perairan,\n",
       " Bahkan,\n",
       " artikel,\n",
       " viral,\n",
       " internet,\n",
       " kotoran,\n",
       " manusia,\n",
       " dijadikan,\n",
       " pakan,\n",
       " budidaya,\n",
       " lele,\n",
       " Kota,\n",
       " Haikou,\n",
       " China,\n",
       " ,\n",
       " Sementara,\n",
       " habitat,\n",
       " aslinya,\n",
       " lele,\n",
       " catfish,\n",
       " dikenal,\n",
       " spesies,\n",
       " ikan,\n",
       " tangguh,\n",
       " Ikan,\n",
       " dilengkapi,\n",
       " alat,\n",
       " pernapasan,\n",
       " tambahan,\n",
       " labirin,\n",
       " bertahan,\n",
       " hidup,\n",
       " kondisi,\n",
       " perairan,\n",
       " berlumpur,\n",
       " tercemar,\n",
       " Agaknya,\n",
       " fakta,\n",
       " memunculkan,\n",
       " dugaan,\n",
       " akumulasi,\n",
       " racun,\n",
       " karsinogen,\n",
       " penyebab,\n",
       " kanker,\n",
       " tubuh,\n",
       " ikan,\n",
       " lele,\n",
       " ,\n",
       " Untungnya,\n",
       " ikan,\n",
       " lele,\n",
       " beredar,\n",
       " pasaran,\n",
       " berasal,\n",
       " alam,\n",
       " liar,\n",
       " Lele,\n",
       " dibudidayakan,\n",
       " kolam,\n",
       " kolam,\n",
       " mestinya,\n",
       " dikendalikan,\n",
       " bebas,\n",
       " pencemaran,\n",
       " Pakan,\n",
       " dipilih,\n",
       " mengandalkan,\n",
       " limbah,\n",
       " ,\n",
       " Yang,\n",
       " popularitas,\n",
       " ikan,\n",
       " bersungut,\n",
       " pudar,\n",
       " meningkat,\n",
       " Data,\n",
       " Kementerian,\n",
       " Kelautan,\n",
       " Perikanan,\n",
       " KKP,\n",
       " menyebut,\n",
       " produksi,\n",
       " lele,\n",
       " 2013,\n",
       " mencapai,\n",
       " 543,461,\n",
       " ton,\n",
       " meningkat,\n",
       " 441,217,\n",
       " ton,\n",
       " 2012,\n",
       " 337,577,\n",
       " ton,\n",
       " 2011,\n",
       " ,\n",
       " Konsumsi,\n",
       " ikan,\n",
       " lele,\n",
       " Badan,\n",
       " Pusat,\n",
       " Statistik,\n",
       " BPS,\n",
       " tercatat,\n",
       " 29,98,\n",
       " kg,\n",
       " kapita,\n",
       " 22,58,\n",
       " kg,\n",
       " kapita,\n",
       " 2004,\n",
       " Di,\n",
       " Jakarta,\n",
       " 6000,\n",
       " lapak,\n",
       " pecel,\n",
       " lele,\n",
       " terdaftar,\n",
       " Asosiasi,\n",
       " Pedagang,\n",
       " Kaki,\n",
       " Lima,\n",
       " Indonesia,\n",
       " APKLI,\n",
       " ,\n",
       " Soal,\n",
       " kandungan,\n",
       " nutrisi,\n",
       " dipungkiri,\n",
       " lele,\n",
       " sumber,\n",
       " protein,\n",
       " berharga,\n",
       " murah,\n",
       " meriah,\n",
       " Fakta,\n",
       " ikan,\n",
       " lele,\n",
       " rendah,\n",
       " kolesterol,\n",
       " menenggelamkan,\n",
       " tudingan,\n",
       " lele,\n",
       " memicu,\n",
       " kanker,\n",
       " Saat,\n",
       " penelitian,\n",
       " memakan,\n",
       " lele,\n",
       " memicu,\n",
       " kanker,\n",
       " dr,\n",
       " Dradjat,\n",
       " R,\n",
       " Suardi,\n",
       " SpB(K)Onk,\n",
       " ahli,\n",
       " kanker,\n",
       " Perhimpunan,\n",
       " Onkologi,\n",
       " Indonesia,\n",
       " dihubungi,\n",
       " detikHealth,\n",
       " Jumat,\n",
       " 23,\n",
       " 10,\n",
       " 2015,\n",
       " ]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop words and Punctuation In List Comprehension\n",
    "[ word for word in docx if word.is_stop == False and not word.is_punct ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the punctuations of string module\n",
    "punctuations = string.punctuation\n",
    "# Creating a Spacy Parser\n",
    "parser = Indonesian()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(sentence):\n",
    "    mytokens = parser(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jakarta',\n",
       " 'jejaring',\n",
       " 'sosial',\n",
       " 'edar',\n",
       " 'informasi',\n",
       " 'lele',\n",
       " 'ikan',\n",
       " 'jorok',\n",
       " 'suap',\n",
       " 'daging',\n",
       " 'ikan',\n",
       " 'lele',\n",
       " 'kandung',\n",
       " '3000',\n",
       " 'sel',\n",
       " 'kanker',\n",
       " 'julukan',\n",
       " 'ikan',\n",
       " 'jorok',\n",
       " 'rujuk',\n",
       " 'sifat',\n",
       " 'lele',\n",
       " 'doyan',\n",
       " 'konsumsi',\n",
       " 'jenis',\n",
       " 'limbah',\n",
       " 'air',\n",
       " 'artikel',\n",
       " 'viral',\n",
       " 'internet',\n",
       " 'kotor',\n",
       " 'manusia',\n",
       " 'dijadikan',\n",
       " 'pakan',\n",
       " 'budidaya',\n",
       " 'lele',\n",
       " 'kota',\n",
       " 'haikou',\n",
       " 'china',\n",
       " 'habitat',\n",
       " 'aslinya',\n",
       " 'lele',\n",
       " 'catfish',\n",
       " 'dikenal',\n",
       " 'spesies',\n",
       " 'ikan',\n",
       " 'tangguh',\n",
       " 'ikan',\n",
       " 'dilengkapi',\n",
       " 'alat',\n",
       " 'napas',\n",
       " 'rupa',\n",
       " 'labirin',\n",
       " 'tahan',\n",
       " 'hidup',\n",
       " 'kondisi',\n",
       " 'air',\n",
       " 'lumpur',\n",
       " 'cemar',\n",
       " 'fakta',\n",
       " 'muncul',\n",
       " 'duga',\n",
       " 'akumulasi',\n",
       " 'racun',\n",
       " 'karsinogen',\n",
       " 'kanker',\n",
       " 'tubuh',\n",
       " 'ikan',\n",
       " 'lele',\n",
       " 'untungnya',\n",
       " 'ikan',\n",
       " 'lele',\n",
       " 'edar',\n",
       " 'pasar',\n",
       " 'alam',\n",
       " 'liar',\n",
       " 'lele',\n",
       " 'dibudidayakan',\n",
       " 'kolam',\n",
       " 'kolam',\n",
       " 'mestinya',\n",
       " 'dikendalikan',\n",
       " 'bebas',\n",
       " 'cemar',\n",
       " 'pakan',\n",
       " 'dipilih',\n",
       " 'andal',\n",
       " 'limbah',\n",
       " 'popularitas',\n",
       " 'ikan',\n",
       " 'sungut',\n",
       " 'pudar',\n",
       " 'tingkat',\n",
       " 'data',\n",
       " 'kementerian',\n",
       " 'kelautan',\n",
       " 'perikanan',\n",
       " 'kkp',\n",
       " 'produksi',\n",
       " 'lele',\n",
       " '2013',\n",
       " 'capai',\n",
       " '543,461',\n",
       " 'ton',\n",
       " 'tingkat',\n",
       " '441,217',\n",
       " 'ton',\n",
       " '2012',\n",
       " '337,577',\n",
       " 'ton',\n",
       " '2011',\n",
       " 'konsumsi',\n",
       " 'ikan',\n",
       " 'lele',\n",
       " 'badan',\n",
       " 'pusat',\n",
       " 'statistik',\n",
       " 'bps',\n",
       " 'catat',\n",
       " '29,98',\n",
       " 'kg',\n",
       " 'kapita',\n",
       " '22,58',\n",
       " 'kg',\n",
       " 'kapita',\n",
       " '2004',\n",
       " 'jakarta',\n",
       " '6000',\n",
       " 'lapak',\n",
       " 'pecel',\n",
       " 'lele',\n",
       " 'daftar',\n",
       " 'asosiasi',\n",
       " 'pedagang',\n",
       " 'kaki',\n",
       " 'indonesia',\n",
       " 'apkli',\n",
       " 'kandung',\n",
       " 'nutrisi',\n",
       " 'dipungkiri',\n",
       " 'lele',\n",
       " 'sumber',\n",
       " 'protein',\n",
       " 'harga',\n",
       " 'murah',\n",
       " 'riah',\n",
       " 'fakta',\n",
       " 'ikan',\n",
       " 'lele',\n",
       " 'rendah',\n",
       " 'kolesterol',\n",
       " 'tenggelam',\n",
       " 'tuding',\n",
       " 'lele',\n",
       " 'picu',\n",
       " 'kanker',\n",
       " 'teliti',\n",
       " 'nyata',\n",
       " 'makan',\n",
       " 'lele',\n",
       " 'picu',\n",
       " 'kanker',\n",
       " 'dr',\n",
       " 'dradjat',\n",
       " 'r',\n",
       " 'suardi',\n",
       " 'spb(k)onk',\n",
       " 'ahli',\n",
       " 'kanker',\n",
       " 'perhimpunan',\n",
       " 'onkologi',\n",
       " 'indonesia',\n",
       " 'dihubungi',\n",
       " 'detikhealth',\n",
       " 'jumat',\n",
       " '23',\n",
       " '10',\n",
       " '2015']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(sampleArticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {}    \n",
    "\n",
    "# Basic function to clean the text \n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "vectorizer = CountVectorizer(tokenizer = tokenizer, ngram_range=(1,1)) \n",
    "classifier = LinearSVC()\n",
    "nbClassifier = GaussianNB()\n",
    "mNbClassifier = MultinomialNB()\n",
    "svmClassifier = svm.SVC()\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "votingClassifier = VotingClassifier(estimators=[('KNN', knnClassifier),\n",
    "                                                ('NaiveBayes', mNbClassifier), \n",
    "                                                ('SVM', svmClassifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tfidf\n",
    "tfvectorizer = TfidfVectorizer(tokenizer = tokenizer, max_df= 0.5, min_df=2, max_features = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Features and Labels\n",
    "X = df['Articles']\n",
    "ylabels = df['Tagging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', tfvectorizer),\n",
    "                 ('to_dense', DenseTransformer()),\n",
    "                 ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cleaner', <__main__.predictors object at 0x1a218a4668>), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=100, min_df=2,\n",
       "        ngram...ormer object at 0x1a218a4f60>), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit our data\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.42      0.53        19\n",
      "          1       0.72      0.90      0.80        31\n",
      "\n",
      "avg / total       0.72      0.72      0.70        50\n",
      "\n",
      "[[ 8 11]\n",
      " [ 3 28]]\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predicting with a test dataset\n",
    "sample_prediction = pipe.predict(X_test)\n",
    "report = classification_report(y_test, sample_prediction)\n",
    "print(report)\n",
    "\n",
    "confusion = confusion_matrix(y_test, sample_prediction)\n",
    "print(confusion)\n",
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]\n",
    "\n",
    "print(FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10d4ff660, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/s...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/rohma.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10d4ff660, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/s...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/rohma.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(15, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(15, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (15, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=15, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 20, 7, 38, 42, 973091, tzinfo=tzutc()), 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'session': 'a13b8d89c8e04665afc2f8ef4fa9fcbb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'a13b8d89c8e04665afc2f8ef4fa9fcbb']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 20, 7, 38, 42, 973091, tzinfo=tzutc()), 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'session': 'a13b8d89c8e04665afc2f8ef4fa9fcbb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'a13b8d89c8e04665afc2f8ef4fa9fcbb'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 20, 7, 38, 42, 973091, tzinfo=tzutc()), 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'session': 'a13b8d89c8e04665afc2f8ef4fa9fcbb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-60-a93d08aaf0bd>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a21f13eb8, execution...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a23f97db0, file \"<ipython-input-60-a93d08aaf0bd>\", line 8>\n        result = <ExecutionResult object at 1a21f13eb8, execution...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a23f97db0, file \"<ipython-input-60-a93d08aaf0bd>\", line 8>, result=<ExecutionResult object at 1a21f13eb8, execution...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a23f97db0, file \"<ipython-input-60-a93d08aaf0bd>\", line 8>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DenseTransformer': <class '__main__.DenseTransformer'>, 'FN': 3, 'FP': 11, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom spacy.lang.id import In...ang.id.stop_words import STOP_WORDS\\nimport string', '# ML Packages\\nfrom sklearn.feature_extraction.te...ingClassifier\\nfrom sklearn import model_selection', 'nlp = Indonesian()', 'df = pd.read_excel(\"News-Articles-Dataset.xls\", sheet_name = \"berita\", na_values = \\' \\')\\ndf.head(10)', \"#Replace tagging with numeric value\\n# 1 for vali...lid', 'hoax'], [1, 0], inplace= True)\\ndf.head(10)\", 'stopwords = list(STOP_WORDS)\\nstopwords', \"sampleArticle = df['Articles'].values[0]\\nsampleArticle\", '#Lemmatization\\ndocx = nlp(sampleArticle)\\nfor wor...ocx: \\n    print(word.text,\"Lemma =>\",word.lemma_)', '# Filtering out Stopwords and Punctuations\\nfor w...ue and not word.is_punct:\\n            print(word)', '# Stop words and Punctuation In List Comprehensi... if word.is_stop == False and not word.is_punct ]', '# Use the punctuations of string module\\npunctuat...n\\n# Creating a Spacy Parser\\nparser = Indonesian()', 'def tokenizer(sentence):\\n    mytokens = parser(s...nd word not in punctuations ]\\n    return mytokens', 'tokenizer(sampleArticle)', '# Custom transformer\\nclass predictors(Transforme..._text(text):     \\n    return text.strip().lower()', \"# Vectorization\\nvectorizer = CountVectorizer(tok...                         ('SVM', svmClassifier)])\", '# Using Tfidf\\ntfvectorizer = TfidfVectorizer(tok...nizer, max_df= 0.5, min_df=2, max_features = 600)', \"# Splitting Data Set\\nfrom sklearn.model_selectio...Labels\\nX = df['Articles']\\nylabels = df['Tagging']\", 'X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)', \"# Create the  pipeline to clean, tokenize, vecto...Transformer()),\\n                 ('clf', SVC())])\", ...], 'Indonesian': <class 'spacy.lang.id.Indonesian'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DenseTransformer': <class '__main__.DenseTransformer'>, 'FN': 3, 'FP': 11, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom spacy.lang.id import In...ang.id.stop_words import STOP_WORDS\\nimport string', '# ML Packages\\nfrom sklearn.feature_extraction.te...ingClassifier\\nfrom sklearn import model_selection', 'nlp = Indonesian()', 'df = pd.read_excel(\"News-Articles-Dataset.xls\", sheet_name = \"berita\", na_values = \\' \\')\\ndf.head(10)', \"#Replace tagging with numeric value\\n# 1 for vali...lid', 'hoax'], [1, 0], inplace= True)\\ndf.head(10)\", 'stopwords = list(STOP_WORDS)\\nstopwords', \"sampleArticle = df['Articles'].values[0]\\nsampleArticle\", '#Lemmatization\\ndocx = nlp(sampleArticle)\\nfor wor...ocx: \\n    print(word.text,\"Lemma =>\",word.lemma_)', '# Filtering out Stopwords and Punctuations\\nfor w...ue and not word.is_punct:\\n            print(word)', '# Stop words and Punctuation In List Comprehensi... if word.is_stop == False and not word.is_punct ]', '# Use the punctuations of string module\\npunctuat...n\\n# Creating a Spacy Parser\\nparser = Indonesian()', 'def tokenizer(sentence):\\n    mytokens = parser(s...nd word not in punctuations ]\\n    return mytokens', 'tokenizer(sampleArticle)', '# Custom transformer\\nclass predictors(Transforme..._text(text):     \\n    return text.strip().lower()', \"# Vectorization\\nvectorizer = CountVectorizer(tok...                         ('SVM', svmClassifier)])\", '# Using Tfidf\\ntfvectorizer = TfidfVectorizer(tok...nizer, max_df= 0.5, min_df=2, max_features = 600)', \"# Splitting Data Set\\nfrom sklearn.model_selectio...Labels\\nX = df['Articles']\\nylabels = df['Tagging']\", 'X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)', \"# Create the  pipeline to clean, tokenize, vecto...Transformer()),\\n                 ('clf', SVC())])\", ...], 'Indonesian': <class 'spacy.lang.id.Indonesian'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/Users/rohmadi.rohmadi/workspace/mine/thesis/<ipython-input-60-a93d08aaf0bd> in <module>()\n      3     \"clf__alpha\": [0.01, 0.1, 0.2, 0.3, 0.4],\n      4     \"clf__fitprior\": [True, False],    \n      5 }\n      6 \n      7 model = GridSearchCV(pipe, param_grid=parameter, cv=3, n_jobs=-1, verbose=1)\n----> 8 model.fit(X_train, y_train)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=1), X=132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, y=132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = 132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object\n        y = 132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Dec 20 14:38:43 2018\nPID: 19211        Python 3.6.5: /Users/rohmadi.rohmadi/anaconda3/bin/python\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), 132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, 132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, {'score': <function _passthrough_scorer>}, array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), 1, {'clf__alpha': 0.01, 'clf__fitprior': True}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), 132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, 132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, {'score': <function _passthrough_scorer>}, array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), 1, {'clf__alpha': 0.01, 'clf__fitprior': True})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), X=132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, y=132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), verbose=1, parameters={'clf__alpha': 0.01, 'clf__fitprior': True}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...alpha=0.01, class_prior=None, fit_prior=True))])>\n        parameters = {'clf__alpha': 0.01, 'clf__fitprior': True}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), **kwargs={'clf__alpha': 0.01, 'clf__fitprior': True})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...alpha=0.01, class_prior=None, fit_prior=True))])>\n        kwargs = {'clf__alpha': 0.01, 'clf__fitprior': True}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), attr='steps', **params={'clf__alpha': 0.01, 'clf__fitprior': True})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...alpha=0.01, class_prior=None, fit_prior=True))])>\n        params = {'clf__alpha': 0.01, 'clf__fitprior': True}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), **params={'clf__alpha': 0.01, 'clf__fitprior': True})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'cleaner': <__main__.predictors object>, 'clf': MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True), 'clf__alpha': 1.0, 'clf__class_prior': None, 'clf__fit_prior': True, 'memory': None, 'steps': [('cleaner', <__main__.predictors object>), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, d...227101e0>, use_idf=True,\n        vocabulary=None)), ('to_dense', <__main__.DenseTransformer object>), ('clf', MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True))], 'to_dense': <__main__.DenseTransformer object>, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, d...227101e0>, use_idf=True,\n        vocabulary=None), 'vectorizer__analyzer': 'word', ...}\n        key.set_params = undefined\n        sub_params = {'alpha': 0.01, 'fitprior': True}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True), **params={'alpha': 0.01, 'fitprior': True})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'fitprior'\n        self = MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter fitprior for estimator MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 444, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 142, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/base.py\", line 282, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/base.py\", line 274, in set_params\n    (key, self))\nValueError: Invalid parameter fitprior for estimator MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Dec 20 14:38:43 2018\nPID: 19211        Python 3.6.5: /Users/rohmadi.rohmadi/anaconda3/bin/python\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), 132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, 132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, {'score': <function _passthrough_scorer>}, array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), 1, {'clf__alpha': 0.01, 'clf__fitprior': True}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), 132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, 132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, {'score': <function _passthrough_scorer>}, array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), 1, {'clf__alpha': 0.01, 'clf__fitprior': True})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), X=132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, y=132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), verbose=1, parameters={'clf__alpha': 0.01, 'clf__fitprior': True}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...alpha=0.01, class_prior=None, fit_prior=True))])>\n        parameters = {'clf__alpha': 0.01, 'clf__fitprior': True}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), **kwargs={'clf__alpha': 0.01, 'clf__fitprior': True})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...alpha=0.01, class_prior=None, fit_prior=True))])>\n        kwargs = {'clf__alpha': 0.01, 'clf__fitprior': True}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), attr='steps', **params={'clf__alpha': 0.01, 'clf__fitprior': True})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...alpha=0.01, class_prior=None, fit_prior=True))])>\n        params = {'clf__alpha': 0.01, 'clf__fitprior': True}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), **params={'clf__alpha': 0.01, 'clf__fitprior': True})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'cleaner': <__main__.predictors object>, 'clf': MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True), 'clf__alpha': 1.0, 'clf__class_prior': None, 'clf__fit_prior': True, 'memory': None, 'steps': [('cleaner', <__main__.predictors object>), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, d...227101e0>, use_idf=True,\n        vocabulary=None)), ('to_dense', <__main__.DenseTransformer object>), ('clf', MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True))], 'to_dense': <__main__.DenseTransformer object>, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, d...227101e0>, use_idf=True,\n        vocabulary=None), 'vectorizer__analyzer': 'word', ...}\n        key.set_params = undefined\n        sub_params = {'alpha': 0.01, 'fitprior': True}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True), **params={'alpha': 0.01, 'fitprior': True})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'fitprior'\n        self = MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter fitprior for estimator MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Dec 20 14:38:43 2018\nPID: 19211        Python 3.6.5: /Users/rohmadi.rohmadi/anaconda3/bin/python\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), 132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, 132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, {'score': <function _passthrough_scorer>}, array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), 1, {'clf__alpha': 0.01, 'clf__fitprior': True}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), 132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, 132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, {'score': <function _passthrough_scorer>}, array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), 1, {'clf__alpha': 0.01, 'clf__fitprior': True})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), X=132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, y=132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), verbose=1, parameters={'clf__alpha': 0.01, 'clf__fitprior': True}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...alpha=0.01, class_prior=None, fit_prior=True))])>\n        parameters = {'clf__alpha': 0.01, 'clf__fitprior': True}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), **kwargs={'clf__alpha': 0.01, 'clf__fitprior': True})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...alpha=0.01, class_prior=None, fit_prior=True))])>\n        kwargs = {'clf__alpha': 0.01, 'clf__fitprior': True}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), attr='steps', **params={'clf__alpha': 0.01, 'clf__fitprior': True})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...alpha=0.01, class_prior=None, fit_prior=True))])>\n        params = {'clf__alpha': 0.01, 'clf__fitprior': True}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), **params={'clf__alpha': 0.01, 'clf__fitprior': True})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'cleaner': <__main__.predictors object>, 'clf': MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True), 'clf__alpha': 1.0, 'clf__class_prior': None, 'clf__fit_prior': True, 'memory': None, 'steps': [('cleaner', <__main__.predictors object>), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, d...227101e0>, use_idf=True,\n        vocabulary=None)), ('to_dense', <__main__.DenseTransformer object>), ('clf', MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True))], 'to_dense': <__main__.DenseTransformer object>, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, d...227101e0>, use_idf=True,\n        vocabulary=None), 'vectorizer__analyzer': 'word', ...}\n        key.set_params = undefined\n        sub_params = {'alpha': 0.01, 'fitprior': True}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True), **params={'alpha': 0.01, 'fitprior': True})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'fitprior'\n        self = MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter fitprior for estimator MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-a93d08aaf0bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10d4ff660, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/s...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/rohma.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10d4ff660, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/s...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/rohma.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(15, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(15, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (15, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=15, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 20, 7, 38, 42, 973091, tzinfo=tzutc()), 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'session': 'a13b8d89c8e04665afc2f8ef4fa9fcbb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'a13b8d89c8e04665afc2f8ef4fa9fcbb']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 20, 7, 38, 42, 973091, tzinfo=tzutc()), 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'session': 'a13b8d89c8e04665afc2f8ef4fa9fcbb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'a13b8d89c8e04665afc2f8ef4fa9fcbb'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 12, 20, 7, 38, 42, 973091, tzinfo=tzutc()), 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'session': 'a13b8d89c8e04665afc2f8ef4fa9fcbb', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'aa395274957b4f199d4a0f9c4e833228', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import GridSearchCV...n_jobs=-1, verbose=1)\\nmodel.fit(X_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-60-a93d08aaf0bd>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1a21f13eb8, execution...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1a23f97db0, file \"<ipython-input-60-a93d08aaf0bd>\", line 8>\n        result = <ExecutionResult object at 1a21f13eb8, execution...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1a23f97db0, file \"<ipython-input-60-a93d08aaf0bd>\", line 8>, result=<ExecutionResult object at 1a21f13eb8, execution...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1a23f97db0, file \"<ipython-input-60-a93d08aaf0bd>\", line 8>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DenseTransformer': <class '__main__.DenseTransformer'>, 'FN': 3, 'FP': 11, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom spacy.lang.id import In...ang.id.stop_words import STOP_WORDS\\nimport string', '# ML Packages\\nfrom sklearn.feature_extraction.te...ingClassifier\\nfrom sklearn import model_selection', 'nlp = Indonesian()', 'df = pd.read_excel(\"News-Articles-Dataset.xls\", sheet_name = \"berita\", na_values = \\' \\')\\ndf.head(10)', \"#Replace tagging with numeric value\\n# 1 for vali...lid', 'hoax'], [1, 0], inplace= True)\\ndf.head(10)\", 'stopwords = list(STOP_WORDS)\\nstopwords', \"sampleArticle = df['Articles'].values[0]\\nsampleArticle\", '#Lemmatization\\ndocx = nlp(sampleArticle)\\nfor wor...ocx: \\n    print(word.text,\"Lemma =>\",word.lemma_)', '# Filtering out Stopwords and Punctuations\\nfor w...ue and not word.is_punct:\\n            print(word)', '# Stop words and Punctuation In List Comprehensi... if word.is_stop == False and not word.is_punct ]', '# Use the punctuations of string module\\npunctuat...n\\n# Creating a Spacy Parser\\nparser = Indonesian()', 'def tokenizer(sentence):\\n    mytokens = parser(s...nd word not in punctuations ]\\n    return mytokens', 'tokenizer(sampleArticle)', '# Custom transformer\\nclass predictors(Transforme..._text(text):     \\n    return text.strip().lower()', \"# Vectorization\\nvectorizer = CountVectorizer(tok...                         ('SVM', svmClassifier)])\", '# Using Tfidf\\ntfvectorizer = TfidfVectorizer(tok...nizer, max_df= 0.5, min_df=2, max_features = 600)', \"# Splitting Data Set\\nfrom sklearn.model_selectio...Labels\\nX = df['Articles']\\nylabels = df['Tagging']\", 'X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)', \"# Create the  pipeline to clean, tokenize, vecto...Transformer()),\\n                 ('clf', SVC())])\", ...], 'Indonesian': <class 'spacy.lang.id.Indonesian'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DenseTransformer': <class '__main__.DenseTransformer'>, 'FN': 3, 'FP': 11, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nfrom spacy.lang.id import In...ang.id.stop_words import STOP_WORDS\\nimport string', '# ML Packages\\nfrom sklearn.feature_extraction.te...ingClassifier\\nfrom sklearn import model_selection', 'nlp = Indonesian()', 'df = pd.read_excel(\"News-Articles-Dataset.xls\", sheet_name = \"berita\", na_values = \\' \\')\\ndf.head(10)', \"#Replace tagging with numeric value\\n# 1 for vali...lid', 'hoax'], [1, 0], inplace= True)\\ndf.head(10)\", 'stopwords = list(STOP_WORDS)\\nstopwords', \"sampleArticle = df['Articles'].values[0]\\nsampleArticle\", '#Lemmatization\\ndocx = nlp(sampleArticle)\\nfor wor...ocx: \\n    print(word.text,\"Lemma =>\",word.lemma_)', '# Filtering out Stopwords and Punctuations\\nfor w...ue and not word.is_punct:\\n            print(word)', '# Stop words and Punctuation In List Comprehensi... if word.is_stop == False and not word.is_punct ]', '# Use the punctuations of string module\\npunctuat...n\\n# Creating a Spacy Parser\\nparser = Indonesian()', 'def tokenizer(sentence):\\n    mytokens = parser(s...nd word not in punctuations ]\\n    return mytokens', 'tokenizer(sampleArticle)', '# Custom transformer\\nclass predictors(Transforme..._text(text):     \\n    return text.strip().lower()', \"# Vectorization\\nvectorizer = CountVectorizer(tok...                         ('SVM', svmClassifier)])\", '# Using Tfidf\\ntfvectorizer = TfidfVectorizer(tok...nizer, max_df= 0.5, min_df=2, max_features = 600)', \"# Splitting Data Set\\nfrom sklearn.model_selectio...Labels\\nX = df['Articles']\\nylabels = df['Tagging']\", 'X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)', \"# Create the  pipeline to clean, tokenize, vecto...Transformer()),\\n                 ('clf', SVC())])\", ...], 'Indonesian': <class 'spacy.lang.id.Indonesian'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/Users/rohmadi.rohmadi/workspace/mine/thesis/<ipython-input-60-a93d08aaf0bd> in <module>()\n      3     \"clf__alpha\": [0.01, 0.1, 0.2, 0.3, 0.4],\n      4     \"clf__fitprior\": [True, False],    \n      5 }\n      6 \n      7 model = GridSearchCV(pipe, param_grid=parameter, cv=3, n_jobs=-1, verbose=1)\n----> 8 model.fit(X_train, y_train)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=1), X=132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, y=132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = 132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object\n        y = 132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Dec 20 14:38:43 2018\nPID: 19211        Python 3.6.5: /Users/rohmadi.rohmadi/anaconda3/bin/python\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), 132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, 132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, {'score': <function _passthrough_scorer>}, array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), 1, {'clf__alpha': 0.01, 'clf__fitprior': True}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), 132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, 132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, {'score': <function _passthrough_scorer>}, array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), 1, {'clf__alpha': 0.01, 'clf__fitprior': True})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), X=132    Sebelumnya sikat gigi bermerek Oral B men...ole...\nName: Articles, Length: 200, dtype: object, y=132    0\n225    1\n238    1\n119    0\n136    0\n66 ...102    1\nName: Tagging, Length: 200, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([ 63,  64,  68,  71,  72,  73,  74,  75,  ..., 192, 193, 194, 195, 196, 197,\n       198, 199]), test=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 1... 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 70]), verbose=1, parameters={'clf__alpha': 0.01, 'clf__fitprior': True}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...alpha=0.01, class_prior=None, fit_prior=True))])>\n        parameters = {'clf__alpha': 0.01, 'clf__fitprior': True}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), **kwargs={'clf__alpha': 0.01, 'clf__fitprior': True})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...alpha=0.01, class_prior=None, fit_prior=True))])>\n        kwargs = {'clf__alpha': 0.01, 'clf__fitprior': True}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), attr='steps', **params={'clf__alpha': 0.01, 'clf__fitprior': True})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...alpha=0.01, class_prior=None, fit_prior=True))])>\n        params = {'clf__alpha': 0.01, 'clf__fitprior': True}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(memory=None,\n     steps=[('cleaner', <_...(alpha=0.01, class_prior=None, fit_prior=True))]), **params={'clf__alpha': 0.01, 'clf__fitprior': True})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'cleaner': <__main__.predictors object>, 'clf': MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True), 'clf__alpha': 1.0, 'clf__class_prior': None, 'clf__fit_prior': True, 'memory': None, 'steps': [('cleaner', <__main__.predictors object>), ('vectorizer', TfidfVectorizer(analyzer='word', binary=False, d...227101e0>, use_idf=True,\n        vocabulary=None)), ('to_dense', <__main__.DenseTransformer object>), ('clf', MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True))], 'to_dense': <__main__.DenseTransformer object>, 'vectorizer': TfidfVectorizer(analyzer='word', binary=False, d...227101e0>, use_idf=True,\n        vocabulary=None), 'vectorizer__analyzer': 'word', ...}\n        key.set_params = undefined\n        sub_params = {'alpha': 0.01, 'fitprior': True}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\n/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self=MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True), **params={'alpha': 0.01, 'fitprior': True})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'fitprior'\n        self = MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter fitprior for estimator MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameter = {\n",
    "    \"clf__alpha\": [0.01, 0.1, 0.2, 0.3, 0.4],\n",
    "    \"clf__fitprior\": [True, False],    \n",
    "}\n",
    "\n",
    "model = GridSearchCV(pipe, param_grid=parameter, cv=3, n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Results\n",
    "# 1 = Valid article\n",
    "# 0 = Hoax article\n",
    "for (sample,pred) in zip(X_test,sample_prediction):\n",
    "    print(sample,\"Prediction=>\",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.82\n",
      "Accuracy:  0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "print(\"Accuracy: \",pipe.score(X_test,y_test))\n",
    "print(\"Accuracy: \",pipe.score(X_test,sample_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohmadi.rohmadi/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "tfvectorizer = TfidfVectorizer(tokenizer = tokenizer, max_df= 0.5, min_df=2, max_features = 100)\n",
    "\n",
    "mNbClassifier = MultinomialNB(alpha=0.1, fit_prior=True, class_prior=None)\n",
    "svmClassifier = svm.SVC()\n",
    "knnClassifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# votingClassifier = VotingClassifier(estimators=[('KNN', knnClassifier),\n",
    "#                                                 ('NaiveBayes', mNbClassifier), \n",
    "#                                                 ('SVM', svmClassifier)])\n",
    "\n",
    "votingClassifier = VotingClassifier(estimators=[('KNN', knnClassifier),\n",
    "                                                ('NaiveBayes', mNbClassifier), \n",
    "                                                ('SVM', svmClassifier)], voting='hard')\n",
    "\n",
    "\n",
    "\n",
    "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', tfvectorizer),\n",
    "                 ('to_dense', DenseTransformer()),\n",
    "                 ('classifier', votingClassifier)])\n",
    "# Fit our data\n",
    "pipe.fit(X_train,y_train)\n",
    "print(\"Accuracy: \",pipe.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= tfvectorizer.fit_transform(df['Articles'])\n",
    "df1 = pd.DataFrame(x.toarray(), columns=tfvectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfvectorizer.get_feature_names()\n",
    "corpus_index = [n for n in corpus]\n",
    "import pandas as pd\n",
    "df3 = pd.DataFrame(tfs.T.todense(), index=feature_names, columns=corpus_index)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# from collections import defaultdict\n",
    "\n",
    "# refsets = defaultdict(set)\n",
    "# testsets = defaultdict(set)\n",
    "# labels = []\n",
    "# tests = []\n",
    "# for i, (feats, label) in enumerate(X_test,sample_prediction):\n",
    "#     refsets[label].add(i)\n",
    "#     observed = classifier.classify(feats)\n",
    "#     testsets[observed].add(i)\n",
    "#     labels.append(label)\n",
    "#     tests.append(observed)\n",
    "\n",
    "# print(metrics.confusion_matrix(labels, tests))\n",
    "\n",
    "# confusion_matrix(X_test,y_test)\n",
    "\n",
    "# from sklearn.ensemble import VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
